{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Time Travel - Exercise Solutions\n",
    "\n",
    "This notebook contains the complete solutions for all time travel exercises. Use this to check your work or understand the concepts better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Exercise 1 Solution: Understanding Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Solution: Define basic math tools\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers together.\n",
    "    \n",
    "    Args:\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\n",
    "    \n",
    "    Args:\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "    \n",
    "    Args:\n",
    "        a: Dividend\n",
    "        b: Divisor\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        return \"Error: Cannot divide by zero\"\n",
    "    return a / b\n",
    "\n",
    "# Solution: Create tools list and LLM with tools\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Solution: Create system message for math assistant\n",
    "sys_msg = SystemMessage(content=\"You are a helpful math assistant. Use the available tools to perform calculations.\")\n",
    "\n",
    "# Solution: Define assistant node\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Solution: Build the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Solution: Compile with memory checkpointer\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Math assistant graph created successfully!\")\n",
    "print(\"This graph will automatically save checkpoints as it executes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Exercise 2 Solution: Creating Your First Execution History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Run your graph with a math problem\n",
    "initial_input = {\"messages\": [HumanMessage(content=\"Calculate 15 * 4 + 8\")]}\n",
    "thread = {\"configurable\": {\"thread_id\": \"exercise_2\"}}\n",
    "\n",
    "print(\"Running graph and creating execution history...\")\n",
    "# Solution: Execute the graph and capture each step\n",
    "step_count = 0\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    step_count += 1\n",
    "    last_message = event['messages'][-1]\n",
    "    msg_type = last_message.__class__.__name__\n",
    "    content_preview = getattr(last_message, 'content', str(last_message))[:80]\n",
    "    print(f\"Step {step_count}: {msg_type} - {content_preview}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Examine the current state\n",
    "current_state = graph.get_state(thread)\n",
    "print(\"Current state information:\")\n",
    "print(f\"Number of messages: {len(current_state.values['messages'])}\")\n",
    "print(f\"Next nodes to execute: {current_state.next}\")\n",
    "print(f\"Checkpoint ID: {current_state.config['configurable']['checkpoint_id']}\")\n",
    "\n",
    "# Solution: Get the complete execution history\n",
    "all_states = [s for s in graph.get_state_history(thread)]\n",
    "print(f\"\\nTotal checkpoints created: {len(all_states)}\")\n",
    "print(\"Each checkpoint represents a step in the execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Exercise 3 Solution: Browsing Execution History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Create a function to analyze execution history\n",
    "def analyze_execution_history(graph, thread_config):\n",
    "    \"\"\"Analyze and display information about execution history.\"\"\"\n",
    "    states = [s for s in graph.get_state_history(thread_config)]\n",
    "    \n",
    "    print(f\"=== Execution History Analysis ({len(states)} checkpoints) ===\")\n",
    "    \n",
    "    for i, state in enumerate(reversed(states)):\n",
    "        print(f\"\\nCheckpoint {i+1}:\")\n",
    "        messages = state.values.get('messages', [])\n",
    "        print(f\"  Messages: {len(messages)}\")\n",
    "        \n",
    "        if messages:\n",
    "            last_msg = messages[-1]\n",
    "            msg_type = last_msg.__class__.__name__\n",
    "            content_preview = getattr(last_msg, 'content', str(last_msg))[:60]\n",
    "            print(f\"  Last message: {msg_type} - {content_preview}...\")\n",
    "        \n",
    "        print(f\"  Next node: {state.next}\")\n",
    "        print(f\"  Checkpoint ID: {state.config['configurable']['checkpoint_id'][:8]}...\")\n",
    "    \n",
    "    return states\n",
    "\n",
    "# Solution: Analyze your execution history\n",
    "history_states = analyze_execution_history(graph, thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Exercise 4 Solution: Time Travel - Replaying from a Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Select a checkpoint to replay from\n",
    "states = [s for s in graph.get_state_history(thread)]\n",
    "# Choose the state with just the human message (should be second from last in reverse order)\n",
    "replay_checkpoint = states[-2]  # This should be the initial state with human message\n",
    "\n",
    "print(f\"Selected checkpoint for replay:\")\n",
    "print(f\"State: {len(replay_checkpoint.values['messages'])} messages\")\n",
    "print(f\"Next: {replay_checkpoint.next}\")\n",
    "if replay_checkpoint.values['messages']:\n",
    "    last_msg_content = replay_checkpoint.values['messages'][-1].content\n",
    "    print(f\"Last message preview: {last_msg_content[:50]}...\")\n",
    "\n",
    "# Solution: Replay execution from this checkpoint\n",
    "print(\"\\n=== REPLAYING FROM CHECKPOINT ===\")\n",
    "replay_step = 0\n",
    "for event in graph.stream(None, replay_checkpoint.config, stream_mode=\"values\"):\n",
    "    replay_step += 1\n",
    "    last_message = event['messages'][-1]\n",
    "    msg_type = last_message.__class__.__name__\n",
    "    content_preview = getattr(last_message, 'content', str(last_message))[:80]\n",
    "    print(f\"Replay Step {replay_step}: {msg_type} - {content_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Exercise 5 Solution: Time Travel - Forking Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Find the initial state with the human message\n",
    "states = [s for s in graph.get_state_history(thread)]\n",
    "initial_state = states[-2]  # State with just the human message\n",
    "\n",
    "print(\"Original query:\", initial_state.values[\"messages\"][0].content)\n",
    "\n",
    "# Solution: Create a modified version of the query\n",
    "original_message = initial_state.values[\"messages\"][0]\n",
    "modified_query = \"Calculate the area of a circle with radius 5\"\n",
    "\n",
    "# Solution: Update the state with the modified query\n",
    "fork_config = graph.update_state(\n",
    "    initial_state.config,\n",
    "    {\"messages\": [HumanMessage(content=modified_query, id=original_message.id)]}\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated fork with new query: {modified_query}\")\n",
    "print(f\"Fork checkpoint ID: {fork_config['configurable']['checkpoint_id'][:8]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Execute the forked path\n",
    "print(\"=== EXECUTING FORKED PATH ===\")\n",
    "fork_step = 0\n",
    "for event in graph.stream(None, fork_config, stream_mode=\"values\"):\n",
    "    fork_step += 1\n",
    "    last_message = event['messages'][-1]\n",
    "    msg_type = last_message.__class__.__name__\n",
    "    content_preview = getattr(last_message, 'content', str(last_message))[:80]\n",
    "    print(f\"Fork Step {fork_step}: {msg_type} - {content_preview}...\")\n",
    "\n",
    "# Solution: Compare the two execution paths\n",
    "print(\"\\n=== COMPARISON ===\")\n",
    "original_final = graph.get_state(thread)\n",
    "forked_final = graph.get_state(fork_config)\n",
    "\n",
    "print(f\"Original result: {original_final.values['messages'][-1].content[:100]}...\")\n",
    "print(f\"Forked result: {forked_final.values['messages'][-1].content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Testing the Complete Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all the basic functionality works\n",
    "print(\"=== TESTING TIME TRAVEL FUNCTIONALITY ===\")\n",
    "\n",
    "# Test 1: Basic execution\n",
    "test_input = {\"messages\": [HumanMessage(content=\"What is 7 * 8?\")]}\n",
    "test_thread = {\"configurable\": {\"thread_id\": \"functionality_test\"}}\n",
    "\n",
    "print(\"\\n1. Testing basic execution with checkpoints...\")\n",
    "for event in graph.stream(test_input, test_thread, stream_mode=\"values\"):\n",
    "    pass  # Just execute to create history\n",
    "\n",
    "# Test 2: History browsing\n",
    "print(\"\\n2. Testing history browsing...\")\n",
    "test_states = [s for s in graph.get_state_history(test_thread)]\n",
    "print(f\"Created {len(test_states)} checkpoints\")\n",
    "\n",
    "# Test 3: Replaying\n",
    "print(\"\\n3. Testing replay functionality...\")\n",
    "replay_state = test_states[-2]\n",
    "replay_count = 0\n",
    "for event in graph.stream(None, replay_state.config, stream_mode=\"values\"):\n",
    "    replay_count += 1\n",
    "print(f\"Replay executed {replay_count} steps\")\n",
    "\n",
    "# Test 4: Forking\n",
    "print(\"\\n4. Testing fork functionality...\")\n",
    "original_msg = replay_state.values[\"messages\"][0]\n",
    "test_fork = graph.update_state(\n",
    "    replay_state.config,\n",
    "    {\"messages\": [HumanMessage(content=\"What is 9 * 9?\", id=original_msg.id)]}\n",
    ")\n",
    "fork_count = 0\n",
    "for event in graph.stream(None, test_fork, stream_mode=\"values\"):\n",
    "    fork_count += 1\n",
    "print(f\"Fork executed {fork_count} steps\")\n",
    "\n",
    "print(\"\\nâœ… All time travel functionality tests passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}