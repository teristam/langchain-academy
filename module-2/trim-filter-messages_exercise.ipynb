{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and Trimming Messages - Practice Exercises\n",
    "\n",
    "## Overview\n",
    "This notebook provides hands-on exercises to practice message management in LangGraph. You'll learn to filter, trim, and manipulate message histories for efficient conversational AI systems.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of these exercises, you will:\n",
    "- Understand MessagesState and message handling in LangGraph\n",
    "- Know how to implement message filtering based on various criteria\n",
    "- Practice message trimming to control context window size\n",
    "- Use RemoveMessage for selective message deletion\n",
    "- Build efficient conversation management systems\n",
    "- Handle token limits and context optimization\n",
    "\n",
    "## Prerequisites\n",
    "- Completed the trim-filter-messages.ipynb tutorial\n",
    "- Understanding of LangChain message types\n",
    "- Basic knowledge of conversational AI concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Optional: Set up LangSmith for tracing\n",
    "# _set_env(\"LANGSMITH_API_KEY\")\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic Message Management\n",
    "\n",
    "### Task\n",
    "Create a simple chatbot that demonstrates basic message handling with MessagesState.\n",
    "\n",
    "### TODO: Set up basic message-based chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# TODO: Initialize the chat model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# TODO: Implement basic chat node\n",
    "def chat_node(state: MessagesState):\n",
    "    print(f\"Processing {len(state['messages'])} messages\")\n",
    "    # TODO: Call the model with the messages and return the response\n",
    "    pass\n",
    "\n",
    "# TODO: Implement message inspector node\n",
    "def inspect_messages(state: MessagesState):\n",
    "    print(\"\\n=== Message Inspection ===\")\n",
    "    for i, msg in enumerate(state['messages']):\n",
    "        print(f\"{i+1}. {type(msg).__name__}: {msg.content[:50]}...\")\n",
    "    print(f\"Total messages: {len(state['messages'])}\")\n",
    "    return {}  # No state updates, just inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build basic chat graph\n",
    "builder_basic = StateGraph(MessagesState)\n",
    "# TODO: Add chat_node and inspect_messages\n",
    "# TODO: Create flow: START -> chat_node -> inspect_messages -> END\n",
    "\n",
    "graph_basic = builder_basic.compile()\n",
    "display(Image(graph_basic.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test basic message handling\n",
    "initial_messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that explains concepts clearly.\"),\n",
    "    HumanMessage(content=\"What is LangGraph?\"),\n",
    "]\n",
    "\n",
    "result_basic = graph_basic.invoke({\"messages\": initial_messages})\n",
    "print(\"\\nFinal conversation:\")\n",
    "for msg in result_basic['messages']:\n",
    "    print(f\"{type(msg).__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Message Filtering by Type and Content\n",
    "\n",
    "### Task\n",
    "Implement various message filtering strategies to manage conversation context.\n",
    "\n",
    "### TODO: Implement message filtering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# TODO: Implement filter to keep only specific message types\n",
    "def filter_by_type(messages: List[BaseMessage], keep_types: List[str]) -> List[BaseMessage]:\n",
    "    \"\"\"Filter messages to keep only specified types.\"\"\"\n",
    "    # TODO: Return only messages whose type names are in keep_types\n",
    "    pass\n",
    "\n",
    "# TODO: Implement filter to remove messages with specific content\n",
    "def filter_by_content(messages: List[BaseMessage], exclude_keywords: List[str]) -> List[BaseMessage]:\n",
    "    \"\"\"Filter out messages containing specific keywords.\"\"\"\n",
    "    # TODO: Remove messages that contain any of the exclude_keywords\n",
    "    pass\n",
    "\n",
    "# TODO: Implement filter to keep only recent messages\n",
    "def filter_recent_messages(messages: List[BaseMessage], max_messages: int) -> List[BaseMessage]:\n",
    "    \"\"\"Keep only the most recent N messages.\"\"\"\n",
    "    # TODO: Return the last max_messages from the list\n",
    "    pass\n",
    "\n",
    "# TODO: Implement smart filter that preserves system messages\n",
    "def smart_filter_preserve_system(messages: List[BaseMessage], max_messages: int) -> List[BaseMessage]:\n",
    "    \"\"\"Filter messages but always preserve system messages.\"\"\"\n",
    "    # TODO: Keep all system messages + most recent non-system messages up to max_messages total\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create test conversation with various message types\n",
    "test_messages = [\n",
    "    SystemMessage(content=\"You are a helpful coding assistant.\"),\n",
    "    HumanMessage(content=\"Help me debug this Python code.\"),\n",
    "    AIMessage(content=\"I'd be happy to help! Please share your code.\"),\n",
    "    HumanMessage(content=\"Here's my buggy code: print('hello world')\"),\n",
    "    AIMessage(content=\"That code looks fine to me. What error are you seeing?\"),\n",
    "    HumanMessage(content=\"Never mind, I found the issue. Thanks!\"),\n",
    "    AIMessage(content=\"Great! Happy to help anytime.\"),\n",
    "    HumanMessage(content=\"Actually, can you help with a different debugging issue?\"),\n",
    "    AIMessage(content=\"Of course! What's the new issue you're facing?\"),\n",
    "]\n",
    "\n",
    "# TODO: Test your filtering functions\n",
    "print(\"Original messages:\", len(test_messages))\n",
    "\n",
    "# Test filter_by_type\n",
    "human_ai_only = filter_by_type(test_messages, [\"HumanMessage\", \"AIMessage\"])\n",
    "print(f\"Human + AI only: {len(human_ai_only)} messages\")\n",
    "\n",
    "# Test filter_by_content  \n",
    "no_debug_messages = filter_by_content(test_messages, [\"debug\", \"buggy\"])\n",
    "print(f\"Excluding debug-related: {len(no_debug_messages)} messages\")\n",
    "\n",
    "# Test filter_recent_messages\n",
    "recent_only = filter_recent_messages(test_messages, 4)\n",
    "print(f\"Recent 4 messages: {len(recent_only)} messages\")\n",
    "\n",
    "# Test smart_filter_preserve_system\n",
    "smart_filtered = smart_filter_preserve_system(test_messages, 5)\n",
    "print(f\"Smart filtered (preserve system): {len(smart_filtered)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Token-Based Message Trimming\n",
    "\n",
    "### Task\n",
    "Implement intelligent message trimming based on token counts to stay within model context limits.\n",
    "\n",
    "### TODO: Implement token-based trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from typing import Tuple\n",
    "\n",
    "# TODO: Initialize tokenizer\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# TODO: Implement token counting function\n",
    "def count_message_tokens(message: BaseMessage) -> int:\n",
    "    \"\"\"Count tokens in a message.\"\"\"\n",
    "    # TODO: Count tokens in message content\n",
    "    pass\n",
    "\n",
    "# TODO: Implement function to count total tokens in message list\n",
    "def count_total_tokens(messages: List[BaseMessage]) -> int:\n",
    "    \"\"\"Count total tokens in a list of messages.\"\"\"\n",
    "    # TODO: Sum up tokens from all messages\n",
    "    pass\n",
    "\n",
    "# TODO: Implement smart trimming function\n",
    "def trim_messages_by_tokens(messages: List[BaseMessage], max_tokens: int) -> Tuple[List[BaseMessage], int]:\n",
    "    \"\"\"Trim messages to fit within token limit, preserving system messages.\"\"\"\n",
    "    # TODO: Implement smart trimming:\n",
    "    # 1. Always keep system messages\n",
    "    # 2. Keep as many recent messages as possible within token limit\n",
    "    # 3. Return (trimmed_messages, total_tokens)\n",
    "    pass\n",
    "\n",
    "# TODO: Implement function that estimates tokens without tokenizer\n",
    "def estimate_tokens(text: str) -> int:\n",
    "    \"\"\"Quick token estimation (roughly 4 chars = 1 token).\"\"\"\n",
    "    # TODO: Implement rough estimation\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create test conversation with varying message lengths\n",
    "long_conversation = [\n",
    "    SystemMessage(content=\"You are an expert software architect with 20 years of experience in distributed systems, microservices, and cloud architecture.\"),\n",
    "    HumanMessage(content=\"I need help designing a scalable e-commerce platform.\"),\n",
    "    AIMessage(content=\"I'd be happy to help you design a scalable e-commerce platform. Let's break this down into key components: user management, product catalog, shopping cart, order processing, payment systems, inventory management, and analytics. Each of these needs to handle high traffic and scale independently.\"),\n",
    "    HumanMessage(content=\"What technologies would you recommend for the backend services?\"),\n",
    "    AIMessage(content=\"For backend services, I recommend a microservices architecture using containerized applications. Consider using Node.js or Python with FastAPI for API services, PostgreSQL for transactional data, Redis for caching and sessions, RabbitMQ or Apache Kafka for message queuing, and Elasticsearch for search functionality. Deploy using Kubernetes on AWS, GCP, or Azure.\"),\n",
    "    HumanMessage(content=\"How should we handle user authentication and authorization?\"),\n",
    "    AIMessage(content=\"Implement OAuth 2.0 with JWT tokens for authentication. Use a dedicated identity service like Auth0, AWS Cognito, or build your own using libraries like Passport.js. Implement role-based access control (RBAC) with permissions stored in your user service. Consider multi-factor authentication for enhanced security.\"),\n",
    "]\n",
    "\n",
    "# TODO: Test token counting and trimming\n",
    "print(\"Token Analysis:\")\n",
    "for i, msg in enumerate(long_conversation):\n",
    "    tokens = count_message_tokens(msg)\n",
    "    print(f\"{i+1}. {type(msg).__name__}: {tokens} tokens\")\n",
    "\n",
    "total_tokens = count_total_tokens(long_conversation)\n",
    "print(f\"\\nTotal tokens: {total_tokens}\")\n",
    "\n",
    "# Test trimming with different limits\n",
    "for limit in [200, 400, 600]:\n",
    "    trimmed, actual_tokens = trim_messages_by_tokens(long_conversation, limit)\n",
    "    print(f\"\\nLimit: {limit} tokens\")\n",
    "    print(f\"Kept: {len(trimmed)} messages, {actual_tokens} tokens\")\n",
    "    for msg in trimmed:\n",
    "        print(f\"  - {type(msg).__name__}: {msg.content[:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Using RemoveMessage for Selective Deletion\n",
    "\n",
    "### Task\n",
    "Implement selective message removal using LangGraph's RemoveMessage functionality.\n",
    "\n",
    "### TODO: Implement selective message removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# TODO: Create state with message management\n",
    "class ConversationState(MessagesState):\n",
    "    message_count: int\n",
    "    last_cleanup: str\n",
    "\n",
    "# TODO: Implement chat node with message tracking\n",
    "def tracked_chat_node(state: ConversationState):\n",
    "    print(f\"Processing conversation (current: {state.get('message_count', 0)} messages)\")\n",
    "    # TODO: Call model and increment message count\n",
    "    response = model.invoke(state['messages'])\n",
    "    # TODO: Return response and updated message_count\n",
    "    pass\n",
    "\n",
    "# TODO: Implement selective cleanup node\n",
    "def cleanup_old_messages(state: ConversationState):\n",
    "    print(\"Cleaning up old messages...\")\n",
    "    messages_to_remove = []\n",
    "    \n",
    "    # TODO: Identify messages to remove based on criteria:\n",
    "    # - Remove messages older than the last 4 messages (keep system messages)\n",
    "    # - Don't remove system messages\n",
    "    # - Create RemoveMessage objects for identified messages\n",
    "    \n",
    "    current_time = \"2024-01-01 12:00:00\"  # Placeholder timestamp\n",
    "    \n",
    "    # TODO: Return RemoveMessage objects and update last_cleanup\n",
    "    pass\n",
    "\n",
    "# TODO: Implement conditional cleanup based on message count\n",
    "def should_cleanup(state: ConversationState) -> str:\n",
    "    # TODO: Return \"cleanup\" if message_count > 8, otherwise \"continue\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build conversation graph with cleanup\n",
    "builder_cleanup = StateGraph(ConversationState)\n",
    "# TODO: Add nodes: tracked_chat_node, cleanup_old_messages\n",
    "# TODO: Add conditional edges based on message count\n",
    "# TODO: Create flow with cleanup when needed\n",
    "\n",
    "# Add memory for persistence\n",
    "memory = MemorySaver()\n",
    "graph_cleanup = builder_cleanup.compile(checkpointer=memory)\n",
    "display(Image(graph_cleanup.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test selective message removal\n",
    "config = {\"configurable\": {\"thread_id\": \"cleanup_test\"}}\n",
    "\n",
    "# Start with system message\n",
    "initial_state = {\n",
    "    \"messages\": [SystemMessage(content=\"You are a helpful assistant.\")],\n",
    "    \"message_count\": 1,\n",
    "    \"last_cleanup\": \"never\"\n",
    "}\n",
    "\n",
    "# Simulate a long conversation\n",
    "conversation_turns = [\n",
    "    \"Hi there!\",\n",
    "    \"How are you doing today?\", \n",
    "    \"What's the weather like?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"What's 2+2?\",\n",
    "    \"Explain quantum computing.\",\n",
    "    \"What's your favorite color?\",\n",
    "    \"How do neural networks work?\"\n",
    "]\n",
    "\n",
    "state = initial_state\n",
    "for turn in conversation_turns:\n",
    "    print(f\"\\n--- Adding: '{turn}' ---\")\n",
    "    state = {**state, \"messages\": state[\"messages\"] + [HumanMessage(content=turn)]}\n",
    "    result = graph_cleanup.invoke(state, config)\n",
    "    \n",
    "    print(f\"Messages in conversation: {len(result['messages'])}\")\n",
    "    print(f\"Last cleanup: {result['last_cleanup']}\")\n",
    "    \n",
    "    state = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Advanced Message Management System\n",
    "\n",
    "### Task\n",
    "Build a sophisticated message management system that combines filtering, trimming, and selective removal with different strategies based on conversation context.\n",
    "\n",
    "### TODO: Implement advanced message management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional\n",
    "import json\n",
    "\n",
    "# TODO: Create advanced conversation state\n",
    "class AdvancedConversationState(MessagesState):\n",
    "    conversation_type: str  # \"casual\", \"technical\", \"support\"\n",
    "    priority_topics: List[str]\n",
    "    token_budget: int\n",
    "    cleanup_strategy: str\n",
    "    conversation_summary: str\n",
    "\n",
    "# TODO: Implement context-aware message analyzer\n",
    "def analyze_conversation_context(state: AdvancedConversationState):\n",
    "    print(\"Analyzing conversation context...\")\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # TODO: Analyze conversation to determine:\n",
    "    # - conversation_type based on content\n",
    "    # - priority_topics from recent messages\n",
    "    # - appropriate token_budget based on type\n",
    "    # - optimal cleanup_strategy\n",
    "    \n",
    "    # Simple analysis logic (enhance this)\n",
    "    technical_keywords = [\"code\", \"algorithm\", \"programming\", \"debug\", \"API\"]\n",
    "    support_keywords = [\"help\", \"issue\", \"problem\", \"error\", \"fix\"]\n",
    "    \n",
    "    # TODO: Implement analysis and return updated state\n",
    "    pass\n",
    "\n",
    "# TODO: Implement adaptive message manager\n",
    "def adaptive_message_management(state: AdvancedConversationState):\n",
    "    print(f\"Managing messages with {state['cleanup_strategy']} strategy\")\n",
    "    \n",
    "    messages = state['messages']\n",
    "    strategy = state['cleanup_strategy']\n",
    "    budget = state['token_budget']\n",
    "    \n",
    "    # TODO: Apply different strategies based on cleanup_strategy:\n",
    "    # - \"aggressive\": Keep only recent + important messages\n",
    "    # - \"conservative\": Trim only when necessary\n",
    "    # - \"topic_focused\": Keep messages related to priority_topics\n",
    "    # - \"token_optimized\": Optimize for token budget\n",
    "    \n",
    "    managed_messages = messages  # TODO: Apply your strategy\n",
    "    \n",
    "    # TODO: Return updated messages and any cleanup actions\n",
    "    pass\n",
    "\n",
    "# TODO: Implement intelligent response node\n",
    "def intelligent_chat_response(state: AdvancedConversationState):\n",
    "    print(f\"Generating {state['conversation_type']} response\")\n",
    "    \n",
    "    # TODO: Customize system prompt based on conversation context\n",
    "    context_prompts = {\n",
    "        \"technical\": \"You are a technical expert. Provide detailed, accurate information.\",\n",
    "        \"support\": \"You are a helpful support agent. Focus on solving the user's problem.\",\n",
    "        \"casual\": \"You are a friendly conversational partner. Keep responses natural and engaging.\"\n",
    "    }\n",
    "    \n",
    "    # TODO: Add context-appropriate system message and get response\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build advanced conversation management graph\n",
    "builder_advanced = StateGraph(AdvancedConversationState)\n",
    "# TODO: Add nodes in sequence:\n",
    "# analyze_conversation_context -> adaptive_message_management -> intelligent_chat_response\n",
    "\n",
    "graph_advanced = builder_advanced.compile()\n",
    "display(Image(graph_advanced.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test advanced message management with different conversation types\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"name\": \"Technical Discussion\",\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"I need help debugging my Python code.\"),\n",
    "            AIMessage(content=\"I'd be happy to help with debugging! What error are you seeing?\"),\n",
    "            HumanMessage(content=\"I'm getting a KeyError when accessing a dictionary.\"),\n",
    "            AIMessage(content=\"KeyError usually means the key doesn't exist. Can you show me the code?\"),\n",
    "            HumanMessage(content=\"Here's the code: data['user_id'] where data comes from an API.\"),\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Support Request\",\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"I'm having trouble logging into my account.\"),\n",
    "            AIMessage(content=\"I can help with login issues. What happens when you try to log in?\"),\n",
    "            HumanMessage(content=\"It says 'invalid credentials' but I'm sure my password is correct.\"),\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Casual Chat\", \n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"What's your favorite movie?\"),\n",
    "            AIMessage(content=\"I enjoy discussing films! What genres do you like?\"),\n",
    "            HumanMessage(content=\"I love sci-fi movies, especially ones about AI.\"),\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"\\n=== Testing: {scenario['name']} ===\")\n",
    "    \n",
    "    initial_advanced_state = {\n",
    "        \"messages\": scenario[\"messages\"],\n",
    "        \"conversation_type\": \"unknown\",\n",
    "        \"priority_topics\": [],\n",
    "        \"token_budget\": 1000,\n",
    "        \"cleanup_strategy\": \"conservative\",\n",
    "        \"conversation_summary\": \"\"\n",
    "    }\n",
    "    \n",
    "    result_advanced = graph_advanced.invoke(initial_advanced_state)\n",
    "    \n",
    "    print(f\"Detected type: {result_advanced['conversation_type']}\")\n",
    "    print(f\"Priority topics: {result_advanced['priority_topics']}\")\n",
    "    print(f\"Cleanup strategy: {result_advanced['cleanup_strategy']}\")\n",
    "    print(f\"Messages managed: {len(result_advanced['messages'])} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise: Dynamic Context Window Management\n",
    "\n",
    "### Task\n",
    "Create a system that dynamically adjusts context window size based on conversation complexity and user preferences, implementing multiple trimming strategies.\n",
    "\n",
    "### TODO: Implement dynamic context management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define dynamic context management state\n",
    "class DynamicContextState(MessagesState):\n",
    "    max_context_tokens: int\n",
    "    context_strategy: str  # \"sliding_window\", \"importance_based\", \"topic_clustering\"\n",
    "    user_preferences: Dict[str, Any]\n",
    "    conversation_complexity: float  # 0.0 to 1.0\n",
    "    message_importance_scores: List[float]\n",
    "\n",
    "# TODO: Implement conversation complexity analyzer\n",
    "def analyze_complexity(state: DynamicContextState) -> float:\n",
    "    \"\"\"Analyze conversation complexity based on various factors.\"\"\"\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # TODO: Calculate complexity based on:\n",
    "    # - Average message length\n",
    "    # - Technical vocabulary usage\n",
    "    # - Question complexity\n",
    "    # - Topic diversity\n",
    "    pass\n",
    "\n",
    "# TODO: Implement importance scorer\n",
    "def score_message_importance(message: BaseMessage, context: List[BaseMessage]) -> float:\n",
    "    \"\"\"Score the importance of a message in context.\"\"\"\n",
    "    # TODO: Score based on:\n",
    "    # - Message type (system messages = high importance)\n",
    "    # - Recency\n",
    "    # - Content relevance to current topic\n",
    "    # - User indicators (questions, requests)\n",
    "    pass\n",
    "\n",
    "# TODO: Implement dynamic trimming strategies\n",
    "def apply_dynamic_trimming(state: DynamicContextState) -> List[BaseMessage]:\n",
    "    \"\"\"Apply dynamic trimming based on state configuration.\"\"\"\n",
    "    messages = state['messages']\n",
    "    strategy = state['context_strategy']\n",
    "    max_tokens = state['max_context_tokens']\n",
    "    \n",
    "    if strategy == \"sliding_window\":\n",
    "        # TODO: Implement sliding window approach\n",
    "        pass\n",
    "    elif strategy == \"importance_based\":\n",
    "        # TODO: Implement importance-based filtering\n",
    "        pass\n",
    "    elif strategy == \"topic_clustering\":\n",
    "        # TODO: Implement topic-based clustering\n",
    "        pass\n",
    "    \n",
    "    return messages  # TODO: Return trimmed messages\n",
    "\n",
    "print(\"Dynamic context management system defined - implement the analysis logic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In these exercises, you've practiced:\n",
    "- Basic message handling with MessagesState in LangGraph\n",
    "- Implementing various message filtering strategies (type, content, recency)\n",
    "- Token-based message trimming to manage context window limits\n",
    "- Using RemoveMessage for selective message deletion\n",
    "- Building sophisticated message management systems with context awareness\n",
    "- Creating adaptive strategies based on conversation characteristics\n",
    "\n",
    "Key takeaways:\n",
    "- **MessagesState**: LangGraph's built-in state for handling conversation messages\n",
    "- **Message Filtering**: Essential for managing conversation context and relevance\n",
    "- **Token Management**: Critical for staying within model context limits\n",
    "- **RemoveMessage**: Powerful tool for selective message cleanup in persistent conversations\n",
    "- **Adaptive Strategies**: Different conversation types benefit from different management approaches\n",
    "- **Context Optimization**: Balance between preserving important information and managing resource constraints\n",
    "\n",
    "These message management techniques are crucial for building production-ready conversational AI systems that can handle long-running conversations efficiently while maintaining context relevance.\n",
    "\n",
    "Next, continue with the chatbot-summarization exercises to learn about creating conversational summaries for long-term memory!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}