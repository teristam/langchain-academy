{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Reducers - Practice Exercises\n",
    "\n",
    "## Overview\n",
    "This notebook provides hands-on exercises to practice working with state reducers in LangGraph. You'll learn how to customize how state updates are applied using different reducer functions.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of these exercises, you will:\n",
    "- Understand the default state update behavior (overwriting)\n",
    "- Know how to use built-in reducers like `add` for lists\n",
    "- Create custom reducers for complex state update logic\n",
    "- Handle concurrent state updates from multiple nodes\n",
    "- Apply reducers to real-world scenarios like accumulating data\n",
    "\n",
    "## Prerequisites\n",
    "- Completed the state-reducers.ipynb tutorial\n",
    "- Understanding of state schema concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Understanding Default Overwriting Behavior\n",
    "\n",
    "### Task\n",
    "Create a simple counter system that demonstrates the default overwriting behavior of LangGraph state updates.\n",
    "\n",
    "### TODO: Implement a basic counter with overwriting behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# TODO: Define a simple state with a counter\n",
    "class CounterState(TypedDict):\n",
    "    # TODO: Add counter field as int\n",
    "    pass\n",
    "\n",
    "# TODO: Implement nodes that increment the counter\n",
    "def increment_by_one(state):\n",
    "    print(f\"Current counter: {state['counter']}, incrementing by 1\")\n",
    "    # TODO: Return new counter value (current + 1)\n",
    "    pass\n",
    "\n",
    "def increment_by_five(state):\n",
    "    print(f\"Current counter: {state['counter']}, incrementing by 5\")\n",
    "    # TODO: Return new counter value (current + 5)\n",
    "    pass\n",
    "\n",
    "def increment_by_ten(state):\n",
    "    print(f\"Current counter: {state['counter']}, incrementing by 10\")\n",
    "    # TODO: Return new counter value (current + 10)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a sequential graph\n",
    "builder = StateGraph(CounterState)\n",
    "# TODO: Add nodes\n",
    "# TODO: Add edges to create: START -> increment_by_one -> increment_by_five -> increment_by_ten -> END\n",
    "\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the sequential execution\n",
    "result = graph.invoke({\"counter\": 0})\n",
    "print(f\"Final counter value: {result['counter']}\")\n",
    "# Expected: 16 (0 + 1 + 5 + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Now test with branching (parallel execution)\n",
    "\n",
    "What happens when multiple nodes run in parallel and update the same state key?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a branching graph where all increment nodes run in parallel\n",
    "builder_parallel = StateGraph(CounterState)\n",
    "# TODO: Add all increment nodes\n",
    "# TODO: Add edges so all three nodes run in parallel from START\n",
    "# All nodes should connect to a final \"collect\" node\n",
    "\n",
    "def collect_results(state):\n",
    "    print(f\"Final collection - counter value: {state['counter']}\")\n",
    "    return {}\n",
    "\n",
    "# TODO: Add collect_results node and connect parallel nodes to it\n",
    "\n",
    "graph_parallel = builder_parallel.compile()\n",
    "display(Image(graph_parallel.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test parallel execution\n",
    "result_parallel = graph_parallel.invoke({\"counter\": 0})\n",
    "print(f\"Final counter value with parallel execution: {result_parallel['counter']}\")\n",
    "# Question: Is this the result you expected? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Using Built-in Reducers\n",
    "\n",
    "### Task\n",
    "Create a shopping cart system that uses the built-in `add` reducer to accumulate items.\n",
    "\n",
    "### TODO: Define state with list reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Annotated\n",
    "from langgraph.graph import add\n",
    "\n",
    "# TODO: Define shopping cart state with list reducer\n",
    "class ShoppingCartState(TypedDict):\n",
    "    # TODO: Use Annotated to specify that items should use the add reducer\n",
    "    # items: Annotated[List[str], add]\n",
    "    total_price: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement nodes that add items to cart\n",
    "def add_electronics(state):\n",
    "    print(\"Adding electronics to cart\")\n",
    "    # TODO: Return dict with items list containing electronics items\n",
    "    items = [\"Laptop\", \"Mouse\", \"Keyboard\"]\n",
    "    # TODO: Also update total_price by adding 1500.0\n",
    "    pass\n",
    "\n",
    "def add_books(state):\n",
    "    print(\"Adding books to cart\")\n",
    "    # TODO: Return dict with items list containing book items\n",
    "    items = [\"Python Programming\", \"Data Science Handbook\"]\n",
    "    # TODO: Also update total_price by adding 80.0\n",
    "    pass\n",
    "\n",
    "def add_groceries(state):\n",
    "    print(\"Adding groceries to cart\")\n",
    "    # TODO: Return dict with items list containing grocery items\n",
    "    items = [\"Apples\", \"Bread\", \"Milk\"]\n",
    "    # TODO: Also update total_price by adding 25.0\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build parallel shopping graph\n",
    "builder_shopping = StateGraph(ShoppingCartState)\n",
    "# TODO: Add all shopping nodes to run in parallel\n",
    "# TODO: Connect to a final checkout node\n",
    "\n",
    "def checkout(state):\n",
    "    print(f\"Checking out with {len(state['items'])} items\")\n",
    "    print(f\"Items: {state['items']}\")\n",
    "    print(f\"Total: ${state['total_price']}\")\n",
    "    return {}\n",
    "\n",
    "graph_shopping = builder_shopping.compile()\n",
    "display(Image(graph_shopping.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test shopping cart with parallel item addition\n",
    "result_shopping = graph_shopping.invoke({\"items\": [], \"total_price\": 0.0})\n",
    "print(f\"Final cart: {result_shopping}\")\n",
    "# The items should be accumulated, not overwritten!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Custom Reducers\n",
    "\n",
    "### Task\n",
    "Create a data analysis system with custom reducers that accumulate statistics from multiple data processing nodes.\n",
    "\n",
    "### TODO: Define custom reducer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "# TODO: Implement custom reducer for merging dictionaries\n",
    "def merge_stats(current: Dict[str, Any], update: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Custom reducer that merges statistics dictionaries.\"\"\"\n",
    "    if current is None:\n",
    "        return update\n",
    "    \n",
    "    merged = current.copy()\n",
    "    # TODO: Implement logic to merge statistics\n",
    "    # For numeric values, add them together\n",
    "    # For lists, concatenate them\n",
    "    # For strings, keep the update value\n",
    "    pass\n",
    "\n",
    "# TODO: Implement custom reducer for accumulating maximum values\n",
    "def max_reducer(current: float, update: float) -> float:\n",
    "    \"\"\"Custom reducer that keeps the maximum value.\"\"\"\n",
    "    # TODO: Return the maximum of current and update\n",
    "    pass\n",
    "\n",
    "# TODO: Implement custom reducer for accumulating minimum values  \n",
    "def min_reducer(current: float, update: float) -> float:\n",
    "    \"\"\"Custom reducer that keeps the minimum value.\"\"\"\n",
    "    # TODO: Return the minimum of current and update (handle None case)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define analytics state with custom reducers\n",
    "class AnalyticsState(TypedDict):\n",
    "    # TODO: Use Annotated with your custom reducers\n",
    "    # stats: Annotated[Dict[str, Any], merge_stats]\n",
    "    # max_value: Annotated[float, max_reducer]  \n",
    "    # min_value: Annotated[float, min_reducer]\n",
    "    dataset_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement data processing nodes\n",
    "def process_user_data(state):\n",
    "    print(\"Processing user data...\")\n",
    "    # TODO: Return stats dict with user data statistics\n",
    "    user_stats = {\n",
    "        \"user_count\": 1000,\n",
    "        \"active_users\": 750,\n",
    "        \"categories\": [\"premium\", \"basic\"]\n",
    "    }\n",
    "    # TODO: Also return max_value and min_value\n",
    "    pass\n",
    "\n",
    "def process_sales_data(state):\n",
    "    print(\"Processing sales data...\")\n",
    "    # TODO: Return stats dict with sales data statistics\n",
    "    sales_stats = {\n",
    "        \"total_sales\": 50000.0,\n",
    "        \"transaction_count\": 500,\n",
    "        \"categories\": [\"electronics\", \"books\"]\n",
    "    }\n",
    "    # TODO: Also return max_value and min_value\n",
    "    pass\n",
    "\n",
    "def process_performance_data(state):\n",
    "    print(\"Processing performance data...\")\n",
    "    # TODO: Return stats dict with performance data statistics\n",
    "    perf_stats = {\n",
    "        \"avg_response_time\": 150.5,\n",
    "        \"error_count\": 5,\n",
    "        \"uptime_percentage\": 99.9\n",
    "    }\n",
    "    # TODO: Also return max_value and min_value\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build analytics processing graph\n",
    "builder_analytics = StateGraph(AnalyticsState)\n",
    "# TODO: Add all processing nodes to run in parallel\n",
    "# TODO: Connect to a report generation node\n",
    "\n",
    "def generate_report(state):\n",
    "    print(\"\\n=== Analytics Report ===\")\n",
    "    print(f\"Dataset: {state['dataset_name']}\")\n",
    "    print(f\"Merged Statistics: {state['stats']}\")\n",
    "    print(f\"Maximum Value: {state['max_value']}\")\n",
    "    print(f\"Minimum Value: {state['min_value']}\")\n",
    "    return {}\n",
    "\n",
    "graph_analytics = builder_analytics.compile()\n",
    "display(Image(graph_analytics.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test analytics processing\n",
    "initial_analytics_state = {\n",
    "    \"stats\": {},\n",
    "    \"max_value\": float('-inf'),\n",
    "    \"min_value\": float('inf'),\n",
    "    \"dataset_name\": \"Q4 Business Analytics\"\n",
    "}\n",
    "\n",
    "result_analytics = graph_analytics.invoke(initial_analytics_state)\n",
    "print(f\"\\nFinal analytics result: {result_analytics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Complex State Management with Multiple Reducers\n",
    "\n",
    "### Task\n",
    "Create a collaborative document editing system where multiple editors can make changes simultaneously. Use different reducers for different types of updates.\n",
    "\n",
    "### TODO: Implement document collaboration system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "from datetime import datetime\n",
    "\n",
    "# TODO: Define custom reducers for document collaboration\n",
    "def merge_content(current: str, update: str) -> str:\n",
    "    \"\"\"Merge document content updates.\"\"\"\n",
    "    # TODO: Implement simple content merging (concatenate with newline)\n",
    "    pass\n",
    "\n",
    "def merge_editors(current: Set[str], update: Set[str]) -> Set[str]:\n",
    "    \"\"\"Merge sets of editors.\"\"\"\n",
    "    # TODO: Implement set union\n",
    "    pass\n",
    "\n",
    "def latest_timestamp(current: str, update: str) -> str:\n",
    "    \"\"\"Keep the latest timestamp.\"\"\"\n",
    "    # TODO: Compare timestamps and return the later one\n",
    "    pass\n",
    "\n",
    "# TODO: Define document collaboration state\n",
    "class DocumentState(TypedDict):\n",
    "    # TODO: Use Annotated with custom reducers\n",
    "    # content: Annotated[str, merge_content]\n",
    "    # editors: Annotated[Set[str], merge_editors]  \n",
    "    # word_count: Annotated[int, add]\n",
    "    # last_modified: Annotated[str, latest_timestamp]\n",
    "    title: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement editor nodes\n",
    "def alice_edit(state):\n",
    "    print(\"Alice is editing the document...\")\n",
    "    # TODO: Return document updates from Alice\n",
    "    content_addition = \"\\n\\nIntroduction:\\nThis document covers the basics of state management.\"\n",
    "    # TODO: Add to content, editors set, word_count, and last_modified\n",
    "    pass\n",
    "\n",
    "def bob_edit(state):\n",
    "    print(\"Bob is editing the document...\")\n",
    "    # TODO: Return document updates from Bob\n",
    "    content_addition = \"\\n\\nAdvanced Topics:\\nWe'll explore complex scenarios and best practices.\"\n",
    "    # TODO: Add to content, editors set, word_count, and last_modified\n",
    "    pass\n",
    "\n",
    "def carol_edit(state):\n",
    "    print(\"Carol is editing the document...\")\n",
    "    # TODO: Return document updates from Carol\n",
    "    content_addition = \"\\n\\nConclusion:\\nState management is crucial for complex applications.\"\n",
    "    # TODO: Add to content, editors set, word_count, and last_modified\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build collaborative editing graph\n",
    "builder_doc = StateGraph(DocumentState)\n",
    "# TODO: Add editor nodes to run in parallel\n",
    "# TODO: Connect to a final review node\n",
    "\n",
    "def review_document(state):\n",
    "    print(\"\\n=== Document Review ===\")\n",
    "    print(f\"Title: {state['title']}\")\n",
    "    print(f\"Editors: {state['editors']}\")\n",
    "    print(f\"Word Count: {state['word_count']}\")\n",
    "    print(f\"Last Modified: {state['last_modified']}\")\n",
    "    print(f\"Content: {state['content']}\")\n",
    "    return {}\n",
    "\n",
    "graph_doc = builder_doc.compile()\n",
    "display(Image(graph_doc.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test collaborative document editing\n",
    "initial_doc_state = {\n",
    "    \"content\": \"State Management Guide\",\n",
    "    \"editors\": set(),\n",
    "    \"word_count\": 3,\n",
    "    \"last_modified\": \"2024-01-01T10:00:00\",\n",
    "    \"title\": \"Complete Guide to State Management\"\n",
    "}\n",
    "\n",
    "result_doc = graph_doc.invoke(initial_doc_state)\n",
    "print(f\"\\nFinal document state keys: {result_doc.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Error Handling in Reducers\n",
    "\n",
    "### Task\n",
    "Create robust reducers that handle edge cases and errors gracefully.\n",
    "\n",
    "### TODO: Implement error-safe reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement safe numeric reducer\n",
    "def safe_add_reducer(current: float, update: float) -> float:\n",
    "    \"\"\"Safely add numeric values, handling None and type errors.\"\"\"\n",
    "    # TODO: Handle None values and type conversion errors\n",
    "    try:\n",
    "        # TODO: Convert to float and add\n",
    "        pass\n",
    "    except (TypeError, ValueError):\n",
    "        # TODO: Return appropriate fallback value\n",
    "        pass\n",
    "\n",
    "# TODO: Implement safe list merger\n",
    "def safe_list_merge(current: List[Any], update: List[Any]) -> List[Any]:\n",
    "    \"\"\"Safely merge lists, handling None values.\"\"\"\n",
    "    # TODO: Handle None values and ensure both inputs are lists\n",
    "    pass\n",
    "\n",
    "# TODO: Implement safe dictionary merger\n",
    "def safe_dict_merge(current: Dict[str, Any], update: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Safely merge dictionaries with conflict resolution.\"\"\"\n",
    "    # TODO: Handle None values and key conflicts\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define state with error-safe reducers\n",
    "class RobustState(TypedDict):\n",
    "    # TODO: Use your safe reducers\n",
    "    # total: Annotated[float, safe_add_reducer]\n",
    "    # items: Annotated[List[Any], safe_list_merge]\n",
    "    # metadata: Annotated[Dict[str, Any], safe_dict_merge]\n",
    "    status: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement nodes that might produce problematic data\n",
    "def node_with_none_values(state):\n",
    "    print(\"Node producing None values...\")\n",
    "    # TODO: Return some None values to test error handling\n",
    "    pass\n",
    "\n",
    "def node_with_wrong_types(state):\n",
    "    print(\"Node producing wrong types...\")\n",
    "    # TODO: Return wrong types to test error handling\n",
    "    pass\n",
    "\n",
    "def node_with_valid_data(state):\n",
    "    print(\"Node producing valid data...\")\n",
    "    # TODO: Return valid data\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build error-testing graph\n",
    "builder_robust = StateGraph(RobustState)\n",
    "# TODO: Add all test nodes\n",
    "# TODO: Connect to validation node\n",
    "\n",
    "def validate_final_state(state):\n",
    "    print(\"\\n=== Final State Validation ===\")\n",
    "    print(f\"Total: {state['total']} (type: {type(state['total'])})\")\n",
    "    print(f\"Items: {state['items']} (type: {type(state['items'])})\")\n",
    "    print(f\"Metadata: {state['metadata']} (type: {type(state['metadata'])})\")\n",
    "    print(f\"Status: {state['status']}\")\n",
    "    return {}\n",
    "\n",
    "graph_robust = builder_robust.compile()\n",
    "display(Image(graph_robust.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test error handling\n",
    "initial_robust_state = {\n",
    "    \"total\": 10.0,\n",
    "    \"items\": [\"initial_item\"],\n",
    "    \"metadata\": {\"version\": 1},\n",
    "    \"status\": \"processing\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    result_robust = graph_robust.invoke(initial_robust_state)\n",
    "    print(\"\\nGraph executed successfully despite problematic inputs!\")\n",
    "except Exception as e:\n",
    "    print(f\"Graph failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise: Dynamic Reducer Selection\n",
    "\n",
    "### Task\n",
    "Create a system where the reducer behavior can change based on the current state or external conditions. This demonstrates advanced reducer patterns.\n",
    "\n",
    "### TODO: Implement dynamic reducer system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement conditional reducer\n",
    "def conditional_number_reducer(current: Dict[str, Any], update: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Reducer that changes behavior based on current state.\"\"\"\n",
    "    # TODO: Implement logic that:\n",
    "    # - If current['mode'] == 'add', add the numbers\n",
    "    # - If current['mode'] == 'multiply', multiply the numbers  \n",
    "    # - If current['mode'] == 'max', keep the maximum\n",
    "    pass\n",
    "\n",
    "# TODO: Define dynamic state\n",
    "class DynamicState(TypedDict):\n",
    "    # TODO: Use the conditional reducer\n",
    "    # data: Annotated[Dict[str, Any], conditional_number_reducer]\n",
    "    mode: str\n",
    "    step: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement nodes that change modes\n",
    "def addition_mode(state):\n",
    "    print(f\"Step {state['step']}: Setting addition mode\")\n",
    "    # TODO: Return mode='add' and some numeric data\n",
    "    pass\n",
    "\n",
    "def multiplication_mode(state):\n",
    "    print(f\"Step {state['step']}: Setting multiplication mode\")\n",
    "    # TODO: Return mode='multiply' and some numeric data\n",
    "    pass\n",
    "\n",
    "def max_mode(state):\n",
    "    print(f\"Step {state['step']}: Setting max mode\")\n",
    "    # TODO: Return mode='max' and some numeric data\n",
    "    pass\n",
    "\n",
    "def increment_step(state):\n",
    "    return {\"step\": state['step'] + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In these exercises, you've practiced:\n",
    "- Understanding default overwriting behavior vs. reducer-based accumulation\n",
    "- Using built-in reducers like `add` for lists\n",
    "- Creating custom reducers for complex state merging logic\n",
    "- Handling errors and edge cases in reducers\n",
    "- Building systems with multiple concurrent state updates\n",
    "\n",
    "Key takeaways:\n",
    "- **Default behavior**: LangGraph overwrites state values by default\n",
    "- **Reducers**: Allow you to customize how state updates are combined\n",
    "- **Built-in reducers**: `add` for lists, basic arithmetic operations\n",
    "- **Custom reducers**: Enable complex merging logic for your specific use cases\n",
    "- **Error handling**: Important for robust production systems\n",
    "- **Parallel execution**: Reducers are essential when multiple nodes update the same state key\n",
    "\n",
    "Next, continue with the multiple-schemas exercises to learn about working with different input/output schemas!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}