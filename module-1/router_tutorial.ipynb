{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/router_tutorial.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239412-lesson-5-router)\n",
        "\n",
        "# Interactive Tutorial: Building Routers in LangGraph\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "\n",
        "1. **Understand routing concepts** - Explain how LLMs can direct control flow in applications\n",
        "2. **Set up tools with chat models** - Bind tools to language models for dynamic execution\n",
        "3. **Build graph nodes** - Create nodes for LLM responses and tool execution\n",
        "4. **Use conditional edges** - Implement routing logic based on LLM output\n",
        "5. **Create complete graphs** - Assemble all components into a functional router\n",
        "6. **Test and validate** - Experiment with different inputs to understand routing behavior\n",
        "\n",
        "## What is a Router?\n",
        "\n",
        "A **router** is a fundamental concept in AI applications where a language model acts as a \"traffic controller,\" deciding whether to:\n",
        "- Provide a direct response to the user\n",
        "- Call one or more tools to gather information or perform actions\n",
        "\n",
        "Think of it like a smart assistant that can either answer directly from knowledge or use specific tools when needed.\n",
        "\n",
        "![Router Concept](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbac6543c3d4df239a4ed1_router1.png)\n",
        "\n",
        "### Real-World Analogy\n",
        "Imagine you're at a restaurant and ask the waiter \"What time is it?\" The waiter might:\n",
        "1. **Direct response**: Look at their watch and tell you the time\n",
        "2. **Tool call**: Use their phone to check the exact time\n",
        "\n",
        "Similarly, our LLM router decides the best approach based on the question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Installing Dependencies\n",
        "\n",
        "Let's start by installing the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langgraph langgraph-prebuilt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's set up our API key. You'll need an OpenAI API key to run this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Understanding Tools and Function Calling\n",
        "\n",
        "### Concept Explanation\n",
        "\n",
        "**Tools** in LangGraph are Python functions that the LLM can call to perform specific tasks. The LLM doesn't execute the code directly - instead, it identifies when a tool should be used and provides the parameters.\n",
        "\n",
        "### Example: Creating a Simple Tool\n",
        "\n",
        "Let's start with a basic multiplication tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool created and bound to LLM successfully!\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "# Create the LLM and bind our tool to it\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "llm_with_tools = llm.bind_tools([multiply])\n",
        "\n",
        "print(\"Tool created and bound to LLM successfully!\")\n",
        "# print(f\"Available tools: {[tool.name for tool in llm_with_tools.bound]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Test Tool Binding\n",
        "\n",
        "Let's test what happens when we ask the LLM a question that might require the multiply tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
            "Response content: \n",
            "Tool calls: [{'name': 'multiply', 'args': {'a': 7, 'b': 9}, 'id': 'call_vWDAqN1WDQeR4E9DANfKMHYJ', 'type': 'tool_call'}]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Test with a multiplication question\n",
        "response = llm_with_tools.invoke([HumanMessage(content=\"What is 7 multiplied by 9?\")])\n",
        "print(\"Response type:\", type(response))\n",
        "print(\"Response content:\", response.content)\n",
        "print(\"Tool calls:\", response.tool_calls if hasattr(response, 'tool_calls') else \"None\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
            "Response content: Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
            "Tool calls: []\n"
          ]
        }
      ],
      "source": [
        "# Now test with a non-multiplication question\n",
        "response2 = llm_with_tools.invoke([HumanMessage(content=\"Hello! How are you today?\")])\n",
        "print(\"Response type:\", type(response2))\n",
        "print(\"Response content:\", response2.content)\n",
        "print(\"Tool calls:\", response2.tool_calls if hasattr(response2, 'tool_calls') else \"None\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection Questions\n",
        "\n",
        "1. What difference did you notice between the two responses?\n",
        "2. When did the LLM decide to use a tool call vs. a direct response?\n",
        "3. What information is included in a tool call?\n",
        "\n",
        "_Take a moment to think about these questions before continuing._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Creating Additional Tools\n",
        "\n",
        "Let's expand our toolkit with more functions to make our router more interesting:\n",
        "\n",
        "### Exercise 2: Create Your Own Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Additional tools created!\n"
          ]
        }
      ],
      "source": [
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers together.\n",
        "    \n",
        "    Args:\n",
        "        a: first number\n",
        "        b: second number\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get the current weather for a city.\n",
        "    \n",
        "    Args:\n",
        "        city: name of the city\n",
        "    \"\"\"\n",
        "    # This is a mock function - in reality, you'd call a weather API\n",
        "    return f\"The weather in {city} is sunny and 72°F\"\n",
        "\n",
        "# TODO: Create your own tool function here!\n",
        "# Try creating a simple calculator function like subtract, divide, or power\n",
        "def subtract(a:int, b:int) -> int:\n",
        "    ''' \n",
        "    Subtract b from a\n",
        "    '''\n",
        "    return a-b\n",
        "\n",
        "print(\"Additional tools created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2a: Complete the Tool\n",
        "\n",
        "Replace the `your_tool_here` function with your own tool. Some ideas:\n",
        "- `subtract(a, b)` - subtract two numbers\n",
        "- `power(base, exponent)` - raise a number to a power\n",
        "- `word_count(text)` - count words in a text\n",
        "- `reverse_string(text)` - reverse a string\n",
        "\n",
        "Make sure to include proper docstrings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Building the Router Graph\n",
        "\n",
        "### Concept: Graph Components\n",
        "\n",
        "A LangGraph router consists of:\n",
        "\n",
        "1. **Nodes**: Functions that process the state\n",
        "   - `tool_calling_llm`: Node that runs the LLM and decides whether to call tools\n",
        "   - `ToolNode`: Node that executes tools when called\n",
        "\n",
        "2. **Edges**: Connections between nodes\n",
        "   - Regular edges: Always go to the next node\n",
        "   - Conditional edges: Route based on conditions (like tool calls)\n",
        "\n",
        "3. **State**: The data that flows through the graph (messages in our case)\n",
        "\n",
        "Let's build our router step by step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM configured with 4 tools\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph import MessagesState\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "# Step 1: Create the LLM with tools\n",
        "tools = [multiply, add, get_weather, subtract]  # Add your tool to this list!\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "print(f\"LLM configured with {len(tools)} tools\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM node defined\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Define the LLM node\n",
        "def tool_calling_llm(state: MessagesState):\n",
        "    \"\"\"Node that processes messages and potentially calls tools.\"\"\"\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"LLM node defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph built successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Build the complete graph\n",
        "builder = StateGraph(MessagesState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Add edges\n",
        "builder.add_edge(START, \"tool_calling_llm\")\n",
        "builder.add_conditional_edges(\n",
        "    \"tool_calling_llm\",\n",
        "    tools_condition,  # This decides: tools if tool_calls exist, END if not\n",
        ")\n",
        "builder.add_edge(\"tools\", END)\n",
        "\n",
        "# Compile the graph\n",
        "graph = builder.compile()\n",
        "\n",
        "print(\"Graph built successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Visualize the Graph\n",
        "\n",
        "Let's see what our graph looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the graph\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Could not display graph image: {e}\")\n",
        "    print(\"Graph structure:\")\n",
        "    print(\"START -> tool_calling_llm -> [conditional] -> tools OR END\")\n",
        "    print(\"tools -> END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the Graph Flow\n",
        "\n",
        "1. **START** → **tool_calling_llm**: Every request begins with the LLM node\n",
        "2. **tool_calling_llm** → **Conditional Edge**: \n",
        "   - If LLM output contains tool calls → go to **tools** node\n",
        "   - If LLM output has no tool calls → go to **END**\n",
        "3. **tools** → **END**: After executing tools, we're done\n",
        "\n",
        "The `tools_condition` function automatically handles this routing logic!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Testing the Router\n",
        "\n",
        "Now comes the fun part - let's test our router with different types of inputs!\n",
        "\n",
        "### Exercise 4a: Test Tool-Requiring Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "QUESTION: What is 15 multiplied by 8?\n",
            "==================================================\n",
            "\n",
            "CONVERSATION FLOW:\n",
            "\n",
            "1. HumanMessage:\n",
            "   Content: What is 15 multiplied by 8?\n",
            "\n",
            "2. AIMessage:\n",
            "   Tool Calls: [{'name': 'multiply', 'args': {'a': 15, 'b': 8}, 'id': 'call_GPRhtb4tXV71uha0mUWlq9B7', 'type': 'tool_call'}]\n",
            "\n",
            "3. ToolMessage:\n",
            "   Content: 120\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is 15 multiplied by 8?', additional_kwargs={}, response_metadata={}, id='15723a47-ea80-45c5-a801-e1dfe993c988'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GPRhtb4tXV71uha0mUWlq9B7', 'function': {'arguments': '{\"a\":15,\"b\":8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 141, 'total_tokens': 158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-CAeMVwAPkXslquehUsqT6LbOu29M2', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--335f5361-6f85-44d4-abff-12590247f00b-0', tool_calls=[{'name': 'multiply', 'args': {'a': 15, 'b': 8}, 'id': 'call_GPRhtb4tXV71uha0mUWlq9B7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 141, 'output_tokens': 17, 'total_tokens': 158, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='120', name='multiply', id='5952df66-0c41-4d22-8e03-90b0a949873f', tool_call_id='call_GPRhtb4tXV71uha0mUWlq9B7')]}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def test_router(question: str):\n",
        "    \"\"\"Helper function to test the router and display results clearly.\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"QUESTION: {question}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    messages = [HumanMessage(content=question)]\n",
        "    result = graph.invoke({\"messages\": messages})\n",
        "    \n",
        "    print(\"\\nCONVERSATION FLOW:\")\n",
        "    for i, message in enumerate(result['messages']):\n",
        "        print(f\"\\n{i+1}. {message.__class__.__name__}:\")\n",
        "        if hasattr(message, 'content') and message.content:\n",
        "            print(f\"   Content: {message.content}\")\n",
        "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "            print(f\"   Tool Calls: {message.tool_calls}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test 1: Mathematical calculation\n",
        "test_router(\"What is 15 multiplied by 8?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 2: Addition\n",
        "test_router(\"Please add 25 and 37\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 3: Weather query\n",
        "test_router(\"What's the weather like in San Francisco?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4b: Test Direct Response Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 4: General greeting\n",
        "test_router(\"Hello! How are you doing today?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 5: General knowledge question\n",
        "test_router(\"What is the capital of France?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 6: Explanation request\n",
        "test_router(\"Can you explain what machine learning is?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4c: Interactive Testing\n",
        "\n",
        "Now it's your turn! Try your own questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try your own questions here!\n",
        "# Some ideas:\n",
        "# - \"What is 12 + 88?\" (should use add tool)\n",
        "# - \"Tell me a joke\" (should respond directly)\n",
        "# - \"What's the weather in Tokyo?\" (should use weather tool)\n",
        "# - \"What is your favorite color?\" (should respond directly)\n",
        "\n",
        "your_question = \"What is 12 + 88?\"  # Replace with your own question\n",
        "test_router(your_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Understanding Router Behavior\n",
        "\n",
        "### Analysis Questions\n",
        "\n",
        "Based on your tests, answer these questions:\n",
        "\n",
        "1. **Pattern Recognition**: What patterns do you notice in when the router chooses tools vs. direct responses?\n",
        "\n",
        "2. **Tool Selection**: How does the LLM decide which specific tool to use when multiple tools are available?\n",
        "\n",
        "3. **Message Flow**: What types of messages do you see in the conversation when tools are called?\n",
        "\n",
        "### Expected Behavior\n",
        "\n",
        "The router should:\n",
        "- **Use tools** for specific computational tasks (math, weather lookup)\n",
        "- **Respond directly** for general conversation, knowledge questions, and explanations\n",
        "- **Choose the right tool** based on the task type\n",
        "- **Show the complete flow** including tool calls and their results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Advanced Exercises\n",
        "\n",
        "### Exercise 6a: Error Handling\n",
        "\n",
        "What happens if we ask for something our tools can't handle?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test error handling\n",
        "test_router(\"Can you divide 10 by 2?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 6b: Multiple Operations\n",
        "\n",
        "Can our router handle requests that might need multiple tools?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test complex requests\n",
        "test_router(\"What is 5 times 7, and also what's the weather in New York?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 6c: Edge Cases\n",
        "\n",
        "Let's test some edge cases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with numbers in text that don't need calculation\n",
        "test_router(\"I have 5 cats and 3 dogs. Tell me about pet care.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with ambiguous mathematical language\n",
        "test_router(\"What do you think about the product of innovation and creativity?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Building Your Own Enhanced Router\n",
        "\n",
        "### Challenge Exercise: Create an Enhanced Router\n",
        "\n",
        "Now it's time to build your own enhanced version! Create a router with at least 5 different tools.\n",
        "\n",
        "#### Requirements:\n",
        "1. Include at least 5 tools of different types\n",
        "2. Test with various inputs\n",
        "3. Document what each tool does\n",
        "4. Show examples of both tool calls and direct responses\n",
        "\n",
        "#### Suggested Tools:\n",
        "- Mathematical operations (subtract, divide, power, etc.)\n",
        "- String operations (reverse, uppercase, word_count)\n",
        "- Data operations (average, max, min from a list)\n",
        "- Date/time operations (current_date, days_between)\n",
        "- Mock API calls (weather, stock prices, currency conversion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your enhanced router here!\n",
        "\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract b from a.\"\"\"\n",
        "    return a - b\n",
        "\n",
        "def word_count(text: str) -> int:\n",
        "    \"\"\"Count the number of words in the text.\"\"\"\n",
        "    return len(text.split())\n",
        "\n",
        "def reverse_string(text: str) -> str:\n",
        "    \"\"\"Reverse the given string.\"\"\"\n",
        "    return text[::-1]\n",
        "\n",
        "# TODO: Add 2 more tools of your choice!\n",
        "\n",
        "# Create your enhanced router\n",
        "enhanced_tools = [multiply, add, subtract, word_count, reverse_string]  # Add your tools here\n",
        "enhanced_llm = llm.bind_tools(enhanced_tools)\n",
        "\n",
        "def enhanced_tool_calling_llm(state: MessagesState):\n",
        "    \"\"\"Enhanced LLM node with more tools.\"\"\"\n",
        "    response = enhanced_llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Build enhanced graph\n",
        "enhanced_builder = StateGraph(MessagesState)\n",
        "enhanced_builder.add_node(\"tool_calling_llm\", enhanced_tool_calling_llm)\n",
        "enhanced_builder.add_node(\"tools\", ToolNode(enhanced_tools))\n",
        "enhanced_builder.add_edge(START, \"tool_calling_llm\")\n",
        "enhanced_builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
        "enhanced_builder.add_edge(\"tools\", END)\n",
        "\n",
        "enhanced_graph = enhanced_builder.compile()\n",
        "\n",
        "print(f\"Enhanced router created with {len(enhanced_tools)} tools!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test your enhanced router\n",
        "def test_enhanced_router(question: str):\n",
        "    \"\"\"Test the enhanced router.\"\"\"\n",
        "    messages = [HumanMessage(content=question)]\n",
        "    result = enhanced_graph.invoke({\"messages\": messages})\n",
        "    \n",
        "    print(f\"\\nQ: {question}\")\n",
        "    print(f\"A: {result['messages'][-1].content}\")\n",
        "    return result\n",
        "\n",
        "# Test cases for your enhanced router\n",
        "test_enhanced_router(\"What is 100 minus 37?\")\n",
        "test_enhanced_router(\"How many words are in 'The quick brown fox jumps over the lazy dog'?\")\n",
        "test_enhanced_router(\"Can you reverse the word 'hello'?\")\n",
        "test_enhanced_router(\"What is artificial intelligence?\")  # Should respond directly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Key Takeaways and Next Steps\n",
        "\n",
        "### Summary\n",
        "\n",
        "Congratulations! You've successfully built and tested LangGraph routers. Here's what you've learned:\n",
        "\n",
        "#### Core Concepts Mastered:\n",
        "1. **Router Pattern**: LLMs can intelligently route between direct responses and tool calls\n",
        "2. **Tool Integration**: Functions can be bound to LLMs for dynamic execution\n",
        "3. **Graph Architecture**: Nodes, edges, and conditional logic work together\n",
        "4. **State Management**: Messages flow through the graph maintaining conversation context\n",
        "5. **Conditional Edges**: `tools_condition` automatically routes based on LLM output\n",
        "\n",
        "#### Key Components:\n",
        "- **MessagesState**: Maintains conversation history\n",
        "- **ToolNode**: Executes tool calls automatically\n",
        "- **tools_condition**: Built-in routing logic\n",
        "- **Conditional edges**: Enable dynamic flow control\n",
        "\n",
        "### Real-World Applications\n",
        "\n",
        "Routers are fundamental to building:\n",
        "- **AI Assistants**: Route between knowledge and tools\n",
        "- **Chatbots**: Handle both conversation and actions\n",
        "- **Agent Systems**: Enable complex multi-step workflows\n",
        "- **API Orchestrators**: Route requests to appropriate services\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Ready to go further? Try these advanced topics:\n",
        "\n",
        "1. **Multiple Router Chains**: Create routers that call other routers\n",
        "2. **Memory Integration**: Add persistent memory to your routers\n",
        "3. **Custom Conditional Logic**: Write your own routing conditions\n",
        "4. **Error Handling**: Add robust error handling and recovery\n",
        "5. **Streaming Responses**: Implement real-time response streaming\n",
        "6. **Multi-Agent Systems**: Coordinate multiple AI agents\n",
        "\n",
        "### Final Challenge\n",
        "\n",
        "Build a \"Smart Assistant\" router that can:\n",
        "- Handle calculations (multiple math operations)\n",
        "- Answer general questions directly\n",
        "- Look up information (weather, definitions, etc.)\n",
        "- Process text (analyze, transform, summarize)\n",
        "- Remember conversation context\n",
        "\n",
        "**Good luck with your LangGraph journey!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection Exercise\n",
        "\n",
        "Before finishing, take a moment to reflect on your learning:\n",
        "\n",
        "1. **What was the most surprising thing you learned about routers?**\n",
        "\n",
        "2. **Which part was most challenging to understand?**\n",
        "\n",
        "3. **What real-world application would you like to build with routers?**\n",
        "\n",
        "4. **What questions do you still have about LangGraph routers?**\n",
        "\n",
        "_Write your thoughts in the cell below:_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Reflections:\n",
        "\n",
        "_Replace this text with your thoughts about the tutorial..._\n",
        "\n",
        "1. Most surprising: \n",
        "2. Most challenging: \n",
        "3. Real-world application idea: \n",
        "4. Questions remaining: \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-academy (3.13.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
