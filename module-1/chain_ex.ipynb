{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Exercises - Interactive Practice\n",
    "\n",
    "Welcome to the interactive chain exercises! This notebook will help you practice the key concepts from the chain lesson:\n",
    "\n",
    "- **Messages**: Working with different message types (HumanMessage, AIMessage, etc.)\n",
    "- **Chat Models**: Using LLMs with message-based conversations\n",
    "- **Tools**: Creating and binding tools to chat models\n",
    "- **LangGraph**: Building graphs with MessagesState and tool calling\n",
    "\n",
    "Each exercise builds on the previous one, so complete them in order!\n",
    "\n",
    "## Setup\n",
    "Let's start by installing the required packages and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Working with Messages üìù\n",
    "\n",
    "**Goal**: Practice creating and working with different message types.\n",
    "\n",
    "LangChain supports several message types:\n",
    "- `HumanMessage`: Messages from users\n",
    "- `AIMessage`: Messages from AI models\n",
    "- `SystemMessage`: Instructions for the AI model\n",
    "- `ToolMessage`: Results from tool calls\n",
    "\n",
    "**Your Task**: Create a conversation between a human and AI about planning a vacation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# TODO: Create a conversation with the following messages:\n",
    "# 1. A SystemMessage with instructions to be a helpful travel assistant\n",
    "# 2. A HumanMessage asking about vacation destinations in Europe\n",
    "# 3. An AIMessage suggesting 3 popular European destinations\n",
    "# 4. A HumanMessage asking for more details about one of the destinations\n",
    "\n",
    "conversation = [\n",
    "    # TODO: Add your messages here\n",
    "    SystemMessage(content='You are a helpful assistant'),\n",
    "    HumanMessage(content='What are the best place to travel in Europe'),\n",
    "    AIMessage(content='London, Pudapest and Switzerland'),\n",
    "    HumanMessage(content='Can you give me more details about Switzerland')\n",
    "    \n",
    "]\n",
    "\n",
    "# Display the conversation\n",
    "for message in conversation:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Hint**: Each message type takes a `content` parameter and optionally a `name` parameter.\n",
    "\n",
    "<details>\n",
    "<summary>üîç Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "conversation = [\n",
    "    SystemMessage(content=\"You are a helpful travel assistant. Provide detailed and accurate information about travel destinations.\"),\n",
    "    HumanMessage(content=\"I'm planning a vacation to Europe. Can you suggest some destinations?\", name=\"Traveler\"),\n",
    "    AIMessage(content=\"Here are 3 popular European destinations: 1) Paris, France - famous for art, culture, and cuisine, 2) Barcelona, Spain - known for architecture and beaches, 3) Amsterdam, Netherlands - beautiful canals and museums.\", name=\"Assistant\"),\n",
    "    HumanMessage(content=\"Tell me more about Barcelona. What's the best time to visit?\", name=\"Traveler\")\n",
    "]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Number of messages: 4\n",
      "‚úÖ Message types: ['SystemMessage', 'HumanMessage', 'AIMessage', 'HumanMessage']\n"
     ]
    }
   ],
   "source": [
    "# Verification: Check your solution\n",
    "print(f\"‚úÖ Number of messages: {len(conversation)}\")\n",
    "print(f\"‚úÖ Message types: {[type(msg).__name__ for msg in conversation]}\")\n",
    "\n",
    "# Expected: 4 messages with types ['SystemMessage', 'HumanMessage', 'AIMessage', 'HumanMessage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Chat Models with Messages ü§ñ\n",
    "\n",
    "**Goal**: Learn to use chat models with message-based input.\n",
    "\n",
    "**Your Task**: Set up a chat model and use it to continue the conversation from Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! Switzerland is renowned for its picturesque landscapes, high-quality living, and diverse cultural experiences. Here are some highlights about Switzerland:\n",
      "\n",
      "1. **Scenic Beauty**: \n",
      "   - **The Alps**: The Swiss Alps offer breathtaking views and numerous outdoor activities throughout the year. During winter, popular ski resorts like Zermatt and St. Moritz attract winter sports enthusiasts. In summer, activities like hiking and mountain biking are popular.\n",
      "   - **Lake Geneva**: This stunning lake, shared with France, is surrounded by the city of Geneva, the Lavaux vineyard terraces, and the historic town of Montreux.\n",
      "   - **Interlaken and Jungfrau Region**: Known for its adventure sports and proximity to majestic peaks like the Eiger, M√∂nch, and Jungfrau.\n",
      "\n",
      "2. **Cities and Culture**:\n",
      "   - **Zurich**: Switzerland's largest city is a hub for finance and culture, offering museums, galleries, and a vibrant nightlife.\n",
      "   - **Geneva**: Known for its Red Cross headquarters and numerous international organizations, Geneva is a city of diplomacy. It also has beautiful parks and a cosmopolitan atmosphere.\n",
      "   - **Bern**: The capital city, with a medieval city center that's a UNESCO World Heritage Site.\n",
      "   - **Lucerne**: Famous for its preserved medieval architecture, crystal-clear lake, and the nearby Rigi and Pilatus mountains.\n",
      "\n",
      "3. **Cuisine**:\n",
      "   - Switzerland is famous for its chocolate and cheese. Traditional dishes include raclette and fondue.\n",
      "   - Try R√∂sti, a potato dish, and taste local wines from regions like the Valais.\n",
      "\n",
      "4. **Transport**:\n",
      "   - Switzerland boasts one of the most efficient and scenic public transportation systems in the world. The Swiss Travel Pass offers unlimited travel on trains, buses, and boats.\n",
      "\n",
      "5. **Languages**:\n",
      "   - Switzerland is multilingual, with four official languages: German, French, Italian, and Romansh. The language spoken varies by region.\n",
      "\n",
      "6. **Shopping and Crafts**:\n",
      "   - Swiss watches are world-renowned, with brands like Rolex and Omega.\n",
      "   - Traditional markets offer local crafts, Swiss Army knives, and artisanal products.\n",
      "\n",
      "Whether you're interested in nature, culture, or simply enjoying a peaceful, well-organized environment, Switzerland offers a unique experience that caters to many interests.\n",
      "\n",
      "Response metadata:\n",
      "Model: gpt-4o-2024-08-06\n",
      "Tokens used: 521\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# TODO: Initialize a ChatOpenAI model with model=\"gpt-4o\"\n",
    "llm = ChatOpenAI(model='gpt-4o')  # Replace with your code\n",
    "\n",
    "# TODO: Use the model to respond to your conversation from Exercise 1\n",
    "# Call llm.invoke() with your conversation messages\n",
    "response = llm.invoke(conversation)  # Replace with your code\n",
    "\n",
    "print(\"AI Response:\")\n",
    "response.pretty_print()\n",
    "\n",
    "print(\"\\nResponse metadata:\")\n",
    "print(f\"Model: {response.response_metadata.get('model_name', 'N/A')}\")\n",
    "print(f\"Tokens used: {response.response_metadata.get('token_usage', {}).get('total_tokens', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üîç Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "response = llm.invoke(conversation)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model initialized: True\n",
      "‚úÖ Response received: True\n",
      "‚úÖ Response is AIMessage: True\n"
     ]
    }
   ],
   "source": [
    "# Verification: Check your solution\n",
    "print(f\"‚úÖ Model initialized: {llm is not None}\")\n",
    "print(f\"‚úÖ Response received: {response is not None}\")\n",
    "print(f\"‚úÖ Response is AIMessage: {type(response).__name__ == 'AIMessage'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Creating and Using Tools üîß\n",
    "\n",
    "**Goal**: Create a custom tool and bind it to a chat model.\n",
    "\n",
    "**Your Task**: Create a temperature conversion tool and test it with the chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m a * b\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# TODO: Bind the tool to your chat model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m llm_with_tools = \u001b[43mllm\u001b[49m.bind_tools([convert_temperature, multiply])  \u001b[38;5;66;03m# Replace with your code\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Test the tool\u001b[39;00m\n\u001b[32m     39\u001b[39m test_message = HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mConvert 25 degrees Celsius to Fahrenheit\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Create a function called 'convert_temperature' that:\n",
    "# - Takes parameters: temperature (float), from_unit (str), to_unit (str)\n",
    "# - Converts between Celsius and Fahrenheit\n",
    "# - Returns the converted temperature as a float\n",
    "# - Has a proper docstring describing the function and parameters\n",
    "\n",
    "def convert_temperature(temperature: float, from_unit: str, to_unit: str) -> float:\n",
    "    \"\"\"\n",
    "    Convert temperature between Celsius and Fahrenheit\n",
    "    \"\"\"\n",
    "    if from_unit.upper() == 'C' and to_unit.upper() == 'F':\n",
    "        return temperature * 9/5 + 32\n",
    "    elif from_unit.upper() == 'F' and to_unit.upper() == 'C':\n",
    "        return (temperature - 32) * 5/9\n",
    "    else:\n",
    "        return temperature  # Same unit, no conversion needed\n",
    "\n",
    "    llm_with_tools = llm.bind_tools([convert_temperature])\n",
    "\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Multiply two numbers together.\n",
    "    \n",
    "    Args:\n",
    "        a: First number to multiply\n",
    "        b: Second number to multiply\n",
    "    \n",
    "    Returns:\n",
    "        The product of a and b\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# TODO: Bind the tool to your chat model\n",
    "llm_with_tools = llm.bind_tools([convert_temperature, multiply])  # Replace with your code\n",
    "\n",
    "# Test the tool\n",
    "test_message = HumanMessage(content=\"Convert 25 degrees Celsius to Fahrenheit\")\n",
    "tool_response = llm_with_tools.invoke([test_message])\n",
    "tool_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Hints**: \n",
    "- Celsius to Fahrenheit: `F = C * 9/5 + 32`\n",
    "- Fahrenheit to Celsius: `C = (F - 32) * 5/9`\n",
    "- Use `llm.bind_tools([your_function])` to bind the tool\n",
    "\n",
    "<details>\n",
    "<summary>üîç Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "def convert_temperature(temperature: float, from_unit: str, to_unit: str) -> float:\n",
    "    \"\"\"Convert temperature between Celsius and Fahrenheit.\n",
    "    \n",
    "    Args:\n",
    "        temperature: The temperature value to convert\n",
    "        from_unit: Source unit ('C' for Celsius, 'F' for Fahrenheit)\n",
    "        to_unit: Target unit ('C' for Celsius, 'F' for Fahrenheit)\n",
    "    \n",
    "    Returns:\n",
    "        The converted temperature\n",
    "    \"\"\"\n",
    "    if from_unit.upper() == 'C' and to_unit.upper() == 'F':\n",
    "        return temperature * 9/5 + 32\n",
    "    elif from_unit.upper() == 'F' and to_unit.upper() == 'C':\n",
    "        return (temperature - 32) * 5/9\n",
    "    else:\n",
    "        return temperature  # Same unit, no conversion needed\n",
    "\n",
    "llm_with_tools = llm.bind_tools([convert_temperature])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Temperature conversion test: 25¬∞C = 77.0¬∞F\n",
      "‚úÖ Expected result: 77.0¬∞F\n",
      "‚úÖ Tool bound to model: True\n",
      "‚úÖ Model has tool calls: True\n"
     ]
    }
   ],
   "source": [
    "# Verification: Test your tool function directly\n",
    "test_result = convert_temperature(25, 'C', 'F')\n",
    "print(f\"‚úÖ Temperature conversion test: 25¬∞C = {test_result}¬∞F\")\n",
    "print(f\"‚úÖ Expected result: 77.0¬∞F\")\n",
    "print(f\"‚úÖ Tool bound to model: {llm_with_tools is not None}\")\n",
    "print(f\"‚úÖ Model has tool calls: {hasattr(tool_response, 'tool_calls') and len(tool_response.tool_calls) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Building a Graph with MessagesState üï∏Ô∏è\n",
    "\n",
    "**Goal**: Create a LangGraph that uses MessagesState and can handle tool calls.\n",
    "\n",
    "**Your Task**: Build a graph that can respond to messages and execute tool calls when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# TODO: Create a node function called 'chatbot' that:\n",
    "# - Takes a MessagesState as input\n",
    "# - Uses llm_with_tools to generate a response\n",
    "# - Returns the response wrapped in a messages list\n",
    "\n",
    "def chatbot(state: MessagesState):\n",
    "    return {'messages': [llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "# TODO: Build the graph:\n",
    "# 1. Create a StateGraph with MessagesState\n",
    "# 2. Add the chatbot node\n",
    "# 3. Add edges from START to chatbot and chatbot to END\n",
    "# 4. Compile the graph\n",
    "\n",
    "class State(MessagesState):\n",
    "    pass\n",
    "\n",
    "builder = StateGraph(State)  # Replace with your code\n",
    "# TODO: Add your graph building code here\n",
    "builder.add_node('chatbot', chatbot)\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "graph = builder.compile()  # Replace with your compiled graph\n",
    "\n",
    "# Display the graph structure\n",
    "if graph:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üîç Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "def chatbot(state: MessagesState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "graph = builder.compile()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Graph created: True\n",
      "‚úÖ Graph nodes: ['__start__', 'chatbot', '__end__']\n",
      "‚úÖ Expected nodes: ['__start__', 'chatbot', '__end__']\n"
     ]
    }
   ],
   "source": [
    "# Verification: Test your graph\n",
    "print(f\"‚úÖ Graph created: {graph is not None}\")\n",
    "if graph:\n",
    "    print(f\"‚úÖ Graph nodes: {list(graph.get_graph().nodes.keys())}\")\n",
    "    print(\"‚úÖ Expected nodes: ['__start__', 'chatbot', '__end__']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Testing the Complete Chain üß™\n",
    "\n",
    "**Goal**: Test your complete chain with different types of inputs.\n",
    "\n",
    "**Your Task**: Test your graph with both regular conversation and tool-requiring queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Regular Conversation ===\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! How are you today?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need! How about you?\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Regular conversation\n",
    "print(\"=== Test 1: Regular Conversation ===\")\n",
    "result1 = graph.invoke({\"messages\": [HumanMessage(content=\"Hello! How are you today?\")]})\n",
    "\n",
    "for msg in result1['messages']:\n",
    "    msg.pretty_print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 2: Temperature Conversion ===\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 100 degrees Fahrenheit in Celsius?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  convert_temperature (call_PXHUPiqKrYbtcPAQzv84UlKu)\n",
      " Call ID: call_PXHUPiqKrYbtcPAQzv84UlKu\n",
      "  Args:\n",
      "    temperature: 100\n",
      "    from_unit: Fahrenheit\n",
      "    to_unit: Celsius\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Tool-requiring query\n",
    "print(\"=== Test 2: Temperature Conversion ===\")\n",
    "result2 = graph.invoke({\"messages\": [HumanMessage(content=\"What is 100 degrees Fahrenheit in Celsius?\")]})\n",
    "\n",
    "for msg in result2['messages']:\n",
    "    msg.pretty_print()\n",
    "    \n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 3: Multi-turn Conversation ===\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm planning a trip to a cold place.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Where are you going?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 10 Celsius in F?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  convert_temperature (call_92i8VAsMtSc0nmUnDNiZ0WCo)\n",
      " Call ID: call_92i8VAsMtSc0nmUnDNiZ0WCo\n",
      "  Args:\n",
      "    temperature: 10\n",
      "    from_unit: Celsius\n",
      "    to_unit: Fahrenheit\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Multi-turn conversation\n",
    "print(\"=== Test 3: Multi-turn Conversation ===\")\n",
    "messages = [\n",
    "    HumanMessage(content=\"I'm planning a trip to a cold place.\"),\n",
    "    AIMessage(content='Where are you going?'),\n",
    "    HumanMessage(content='What is 10 Celsius in F?')\n",
    "]\n",
    "\n",
    "# TODO: Use your graph to continue this conversation\n",
    "result3 = graph.invoke({'messages':messages})  # Replace with your code\n",
    "\n",
    "if result3:\n",
    "    for msg in result3['messages']:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üîç Click to see the solution for Test 3</summary>\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    HumanMessage(content=\"I'm planning a trip to a cold place.\"),\n",
    "    AIMessage(content=\"That sounds exciting! Cold destinations can be beautiful. Are you thinking about somewhere like Alaska, Norway, or maybe Iceland?\"),\n",
    "    HumanMessage(content=\"Iceland sounds great! I heard it can be -10¬∞C there. What is that in Fahrenheit?\")\n",
    "]\n",
    "\n",
    "result3 = graph.invoke({\"messages\": messages})\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ FINAL VERIFICATION üéâ\n",
      "‚úÖ Test 1 completed: True\n",
      "‚úÖ Test 2 completed: True\n",
      "‚úÖ Test 2 used tools: True\n",
      "‚úÖ Test 3 completed: True\n",
      "\n",
      "üèÜ Congratulations! You've successfully built a complete chain with:\n",
      "   üìù Message handling\n",
      "   ü§ñ Chat model integration\n",
      "   üîß Custom tool creation\n",
      "   üï∏Ô∏è LangGraph state management\n",
      "   üß™ End-to-end testing\n"
     ]
    }
   ],
   "source": [
    "# Final Verification: Check all tests\n",
    "print(\"üéâ FINAL VERIFICATION üéâ\")\n",
    "print(f\"‚úÖ Test 1 completed: {result1 is not None and len(result1['messages']) > 0}\")\n",
    "print(f\"‚úÖ Test 2 completed: {result2 is not None and len(result2['messages']) > 0}\")\n",
    "if result2 and len(result2['messages']) > 1:\n",
    "    last_msg = result2['messages'][-1]\n",
    "    has_tool_call = hasattr(last_msg, 'tool_calls') and len(last_msg.tool_calls) > 0\n",
    "    print(f\"‚úÖ Test 2 used tools: {has_tool_call}\")\n",
    "print(f\"‚úÖ Test 3 completed: {result3 is not None and len(result3['messages']) > 0 if result3 else False}\")\n",
    "\n",
    "print(\"\\nüèÜ Congratulations! You've successfully built a complete chain with:\")\n",
    "print(\"   üìù Message handling\")\n",
    "print(\"   ü§ñ Chat model integration\")\n",
    "print(\"   üîß Custom tool creation\")\n",
    "print(\"   üï∏Ô∏è LangGraph state management\")\n",
    "print(\"   üß™ End-to-end testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Bonus Challenges\n",
    "\n",
    "If you want to practice more, try these bonus challenges:\n",
    "\n",
    "### Challenge 1: Add More Tools\n",
    "Create additional tools like:\n",
    "- A calculator for basic math operations\n",
    "- A unit converter for distances (miles to km)\n",
    "- A time zone converter\n",
    "\n",
    "### Challenge 2: Error Handling\n",
    "Modify your temperature conversion tool to handle invalid inputs gracefully.\n",
    "\n",
    "### Challenge 3: Conversation Memory\n",
    "Extend your graph to remember previous conversations by maintaining message history.\n",
    "\n",
    "### Challenge 4: Conditional Logic\n",
    "Add conditional edges to your graph that route to different nodes based on the type of user request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your bonus challenges!\n",
    "# TODO: Implement your bonus challenges here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-academy (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
