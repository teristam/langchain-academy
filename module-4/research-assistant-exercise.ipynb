{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/research-assistant-exercise.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239974-lesson-4-research-assistant)\n",
    "\n",
    "# Research Assistant - Exercise Notebook\n",
    "\n",
    "Welcome to the research assistant exercise notebook! In this interactive session, you'll build your own multi-agent research system using LangGraph.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of these exercises, you will be able to:\n",
    "\n",
    "1. **Design Multi-Agent Systems**: Create analyst personas with specific roles and expertise areas\n",
    "2. **Implement Human-in-the-Loop**: Build interactive workflows where humans can provide feedback and refine AI-generated content\n",
    "3. **Build Interview Workflows**: Create conversational agents that conduct structured interviews with experts\n",
    "4. **Use Parallel Processing**: Leverage LangGraph's `Send()` API for map-reduce patterns\n",
    "5. **Integrate Multiple Data Sources**: Combine web search, Wikipedia, and other sources for comprehensive research\n",
    "6. **Create Report Generation Pipelines**: Transform raw research into structured, professional reports\n",
    "\n",
    "## Exercise Structure\n",
    "\n",
    "This notebook contains **5 progressive exercises**:\n",
    "\n",
    "- **Exercise 1**: Basic Analyst Generation (Beginner)\n",
    "- **Exercise 2**: Human Feedback Loop (Intermediate) \n",
    "- **Exercise 3**: Expert Interview System (Intermediate)\n",
    "- **Exercise 4**: Multi-Source Research Integration (Advanced)\n",
    "- **Exercise 5**: Complete Research Assistant Pipeline (Advanced)\n",
    "\n",
    "Each exercise builds upon the previous one, gradually increasing in complexity.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by installing the required packages and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langchain_community langchain_core tavily-python wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Set up tracing\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display, Markdown\n",
    "import operator\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 1: Basic Analyst Generation (Beginner)\n",
    "\n",
    "## Objective\n",
    "Create a system that generates AI analyst personas for a given research topic.\n",
    "\n",
    "## Background\n",
    "The foundation of a good research assistant is having diverse perspectives. Different analysts bring unique viewpoints, expertise areas, and concerns to research topics.\n",
    "\n",
    "## Your Task\n",
    "\n",
    "1. **Define Data Models**: Create Pydantic models for `Analyst` and `Perspectives`\n",
    "2. **Create State Schema**: Define a TypedDict for managing analyst generation state\n",
    "3. **Implement Analyst Generator**: Write a function that uses structured LLM output to create analysts\n",
    "4. **Test Your Implementation**: Generate analysts for a sample topic\n",
    "\n",
    "### Step 1: Define the Analyst Model\n",
    "\n",
    "Complete the `Analyst` class below. Each analyst should have:\n",
    "- `name`: The analyst's name\n",
    "- `affiliation`: Their organization or company\n",
    "- `role`: Their job title or role\n",
    "- `description`: A detailed description of their focus and expertise\n",
    "- `persona` property: A formatted string combining all analyst information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyst(BaseModel):\n",
    "    # TODO: Add fields for affiliation, name, role, and description\n",
    "    # Use Field() with descriptions for each\n",
    "    \n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        # TODO: Return a formatted string with analyst information\n",
    "        # Format: \"Name: {name}\\nRole: {role}\\nAffiliation: {affiliation}\\nDescription: {description}\\n\"\n",
    "        pass\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    # TODO: Add a field for a list of analysts\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create State Schema\n",
    "\n",
    "Define a TypedDict for managing the analyst generation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalystGenerationState(TypedDict):\n",
    "    # TODO: Add fields for:\n",
    "    # - topic: str (the research topic)\n",
    "    # - max_analysts: int (maximum number of analysts to generate)\n",
    "    # - analysts: List[Analyst] (the generated analysts)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Analyst Generator\n",
    "\n",
    "Create a function that generates analysts based on a topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
    "\n",
    "1. First, review the research topic: {topic}\n",
    "        \n",
    "2. Determine the most interesting themes and perspectives for this topic.\n",
    "                    \n",
    "3. Pick the top {max_analysts} themes.\n",
    "\n",
    "4. Assign one analyst to each theme, ensuring diversity in:\n",
    "   - Professional backgrounds\n",
    "   - Industry affiliations\n",
    "   - Areas of expertise\n",
    "   - Potential concerns or interests\n",
    "\n",
    "5. Make each analyst realistic and specific to their domain.\"\"\"\n",
    "\n",
    "def create_analysts(state: AnalystGenerationState):\n",
    "    \"\"\" Create analysts based on topic and max count \"\"\"\n",
    "    \n",
    "    # TODO: Extract topic and max_analysts from state\n",
    "    \n",
    "    # TODO: Create a structured LLM that outputs Perspectives\n",
    "    # Use: llm.with_structured_output(Perspectives)\n",
    "    \n",
    "    # TODO: Format the system message with topic and max_analysts\n",
    "    \n",
    "    # TODO: Invoke the structured LLM with system message and human message\n",
    "    \n",
    "    # TODO: Return the analysts in the correct state format\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Test Your Implementation\n",
    "\n",
    "Create a simple graph and test your analyst generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a StateGraph with AnalystGenerationState\n",
    "# Add the create_analysts node\n",
    "# Connect START -> create_analysts -> END\n",
    "# Compile the graph\n",
    "\n",
    "# Test with this topic:\n",
    "test_topic = \"The impact of artificial intelligence on healthcare diagnostics\"\n",
    "max_analysts = 3\n",
    "\n",
    "# Run the graph and print results\n",
    "# result = graph.invoke({\"topic\": test_topic, \"max_analysts\": max_analysts})\n",
    "# for analyst in result['analysts']:\n",
    "#     print(f\"Name: {analyst.name}\")\n",
    "#     print(f\"Affiliation: {analyst.affiliation}\")\n",
    "#     print(f\"Role: {analyst.role}\")\n",
    "#     print(f\"Description: {analyst.description}\")\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Checkpoint 1**: Verify Your Solution\n",
    "\n",
    "Your analyst generator should:\n",
    "- âœ… Create exactly the requested number of analysts\n",
    "- âœ… Generate diverse perspectives relevant to the topic\n",
    "- âœ… Include realistic names, affiliations, and roles\n",
    "- âœ… Provide detailed descriptions of each analyst's focus\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Human Feedback Loop (Intermediate)\n",
    "\n",
    "## Objective\n",
    "Extend your analyst generation system to include human-in-the-loop feedback for refining analyst selection.\n",
    "\n",
    "## Background\n",
    "Real-world research assistants need human oversight. Users should be able to review generated analysts and provide feedback to improve the selection before proceeding with research.\n",
    "\n",
    "## Your Task\n",
    "\n",
    "1. **Extend State Schema**: Add human feedback capability\n",
    "2. **Create Feedback Node**: Implement a human feedback interruption point\n",
    "3. **Add Conditional Logic**: Route based on feedback presence\n",
    "4. **Test Interactive Flow**: Experience the human-in-the-loop workflow\n",
    "\n",
    "### Step 1: Extend State Schema\n",
    "\n",
    "Update your state to include human feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAnalystState(TypedDict):\n",
    "    topic: str\n",
    "    max_analysts: int\n",
    "    analysts: List[Analyst]\n",
    "    # TODO: Add human_analyst_feedback: str field\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Update Analyst Creation Function\n",
    "\n",
    "Modify your analyst creation to consider human feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_analyst_instructions = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
    "\n",
    "1. First, review the research topic: {topic}\n",
    "        \n",
    "2. Examine any editorial feedback that has been provided to guide creation of the analysts: \n",
    "{human_analyst_feedback}\n",
    "    \n",
    "3. Determine the most interesting themes based upon the topic and feedback above.\n",
    "                    \n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one analyst to each theme, incorporating any specific feedback provided.\"\"\"\n",
    "\n",
    "def create_analysts_with_feedback(state: EnhancedAnalystState):\n",
    "    \"\"\" Create analysts, considering human feedback if provided \"\"\"\n",
    "    \n",
    "    topic = state['topic']\n",
    "    max_analysts = state['max_analysts']\n",
    "    # TODO: Get human_analyst_feedback from state, default to empty string if not present\n",
    "    \n",
    "    # TODO: Create structured LLM\n",
    "    \n",
    "    # TODO: Format system message with topic, feedback, and max_analysts\n",
    "    \n",
    "    # TODO: Generate analysts and return in state format\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Human Feedback Components\n",
    "\n",
    "Implement the feedback node and routing logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state: EnhancedAnalystState):\n",
    "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
    "    # TODO: This should be a pass-through node\n",
    "    # The interruption happens in the graph compilation\n",
    "    pass\n",
    "\n",
    "def should_continue(state: EnhancedAnalystState):\n",
    "    \"\"\" Determine next node based on feedback presence \"\"\"\n",
    "    \n",
    "    # TODO: Check if human_analyst_feedback exists and is not None/empty\n",
    "    # If feedback exists, return \"create_analysts\" to regenerate\n",
    "    # Otherwise, return END\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Interactive Graph\n",
    "\n",
    "Create a graph with human-in-the-loop functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create StateGraph with EnhancedAnalystState\n",
    "# Add nodes: create_analysts_with_feedback, human_feedback\n",
    "# Add edges: START -> create_analysts_with_feedback -> human_feedback\n",
    "# Add conditional edge: human_feedback -> should_continue -> [\"create_analysts_with_feedback\", END]\n",
    "# Compile with interrupt_before=['human_feedback'] and MemorySaver checkpointer\n",
    "\n",
    "# Display the graph\n",
    "# display(Image(interactive_graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test Interactive Flow\n",
    "\n",
    "Experience the human feedback workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up initial parameters\n",
    "topic = \"The future of renewable energy storage technologies\"\n",
    "max_analysts = 3\n",
    "thread = {\"configurable\": {\"thread_id\": \"exercise_2\"}}\n",
    "\n",
    "# TODO: Run until first interruption\n",
    "# Use graph.stream() with stream_mode=\"values\"\n",
    "# Print analysts when they appear in events\n",
    "\n",
    "print(\"Initial analysts generated. Waiting for human feedback...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Provide feedback using graph.update_state()\n",
    "# Example feedback: \"Add a policy analyst focused on government regulations and incentives\"\n",
    "# Use as_node=\"human_feedback\"\n",
    "\n",
    "feedback = \"Add a policy analyst focused on government regulations and incentives\"\n",
    "# graph.update_state(thread, {\"human_analyst_feedback\": feedback}, as_node=\"human_feedback\")\n",
    "\n",
    "print(f\"Feedback provided: {feedback}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Continue execution after feedback\n",
    "# Use graph.stream(None, thread, stream_mode=\"values\")\n",
    "# Print the updated analysts\n",
    "\n",
    "print(\"Updated analysts after feedback:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Checkpoint 2**: Verify Your Solution\n",
    "\n",
    "Your interactive system should:\n",
    "- âœ… Generate initial analysts and pause for feedback\n",
    "- âœ… Accept human feedback and regenerate analysts accordingly\n",
    "- âœ… Allow multiple rounds of feedback if needed\n",
    "- âœ… Proceed to completion when no feedback is provided\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Expert Interview System (Intermediate)\n",
    "\n",
    "## Objective\n",
    "Build an interview system where AI analysts conduct multi-turn conversations with AI experts to gather insights.\n",
    "\n",
    "## Background\n",
    "The heart of the research assistant is conducting thorough interviews. Analysts ask questions, experts search for information and provide answers, and the conversation continues until sufficient insights are gathered.\n",
    "\n",
    "## Your Task\n",
    "\n",
    "1. **Design Interview State**: Create state schema for managing conversations\n",
    "2. **Build Question Generator**: Implement analyst question generation\n",
    "3. **Create Search Functions**: Add web and Wikipedia search capabilities\n",
    "4. **Implement Answer Generator**: Create expert response system\n",
    "5. **Add Conversation Control**: Manage interview flow and termination\n",
    "\n",
    "### Step 1: Define Interview State\n",
    "\n",
    "Create a state schema for managing interviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewState(MessagesState):\n",
    "    # TODO: Add the following fields:\n",
    "    # - max_num_turns: int (maximum conversation turns)\n",
    "    # - context: Annotated[list, operator.add] (source documents)\n",
    "    # - analyst: Analyst (the analyst conducting interview)\n",
    "    # - interview: str (final interview transcript)\n",
    "    pass\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    # TODO: Add search_query field with appropriate description\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Question Generation\n",
    "\n",
    "Create a function for analysts to generate interview questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic. \n",
    "\n",
    "Your goal is to gather interesting and specific insights related to your area of expertise.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "2. Specific: Insights that avoid generalities and include specific examples.\n",
    "\n",
    "Here is your area of focus: {goals}\n",
    "        \n",
    "Begin by introducing yourself using your name, and then ask your question.\n",
    "\n",
    "Continue to ask follow-up questions to drill down and refine your understanding.\n",
    "        \n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Stay in character throughout your response.\"\"\"\n",
    "\n",
    "def generate_question(state: InterviewState):\n",
    "    \"\"\" Generate analyst question \"\"\"\n",
    "    \n",
    "    # TODO: Extract analyst and messages from state\n",
    "    \n",
    "    # TODO: Create system message using question_instructions template\n",
    "    # Format with analyst.persona as goals\n",
    "    \n",
    "    # TODO: Invoke LLM with system message + existing messages\n",
    "    \n",
    "    # TODO: Return new message in messages list\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Search Functions\n",
    "\n",
    "Implement web and Wikipedia search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up search tools\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "\n",
    "# Search query instructions\n",
    "search_instructions = SystemMessage(content=\"\"\"You will be given a conversation between an analyst and an expert. \n",
    "\n",
    "Your goal is to generate a well-structured query for retrieval and web search.\n",
    "        \n",
    "Analyze the full conversation and pay particular attention to the final question posed by the analyst.\n",
    "\n",
    "Convert this final question into a well-structured web search query.\"\"\")\n",
    "\n",
    "def search_web(state: InterviewState):\n",
    "    \"\"\" Search web for relevant information \"\"\"\n",
    "    \n",
    "    # TODO: Create structured LLM for SearchQuery\n",
    "    \n",
    "    # TODO: Generate search query from conversation messages\n",
    "    \n",
    "    # TODO: Use tavily_search.invoke() to get search results\n",
    "    \n",
    "    # TODO: Format search results as documents with <Document> tags\n",
    "    # Format: '<Document href=\"{url}\"/>\\n{content}\\n</Document>'\n",
    "    \n",
    "    # TODO: Return formatted docs in context list\n",
    "    pass\n",
    "\n",
    "def search_wikipedia(state: InterviewState):\n",
    "    \"\"\" Search Wikipedia for relevant information \"\"\"\n",
    "    \n",
    "    # TODO: Similar to search_web but use WikipediaLoader\n",
    "    # Load max 2 documents\n",
    "    # Format with source and page metadata\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Answer Generation\n",
    "\n",
    "Create the expert response system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "\n",
    "Here is the analyst's area of focus: {goals}\n",
    "        \n",
    "Your goal is to answer the question posed by the interviewer using this context:\n",
    "        \n",
    "{context}\n",
    "\n",
    "Guidelines:\n",
    "        \n",
    "1. Use only information provided in the context.\n",
    "2. Do not introduce external information beyond what is in the context.\n",
    "3. Include source citations using [1], [2], etc.\n",
    "4. List sources at the end of your answer.\n",
    "5. Be specific and provide concrete examples when available.\"\"\"\n",
    "\n",
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\" Generate expert answer using search context \"\"\"\n",
    "    \n",
    "    # TODO: Extract analyst, messages, and context from state\n",
    "    \n",
    "    # TODO: Format system message with analyst goals and context\n",
    "    \n",
    "    # TODO: Generate answer using LLM\n",
    "    \n",
    "    # TODO: Set answer.name = \"expert\"\n",
    "    \n",
    "    # TODO: Return answer in messages list\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Add Interview Control\n",
    "\n",
    "Implement conversation flow management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string\n",
    "\n",
    "def route_conversation(state: InterviewState):\n",
    "    \"\"\" Route between continuing questions or ending interview \"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state.get('max_num_turns', 3)\n",
    "\n",
    "    # TODO: Count expert responses (messages with name=\"expert\")\n",
    "    \n",
    "    # TODO: If expert responses >= max_num_turns, return 'end_interview'\n",
    "    \n",
    "    # TODO: Check if last question contains \"Thank you so much for your help\"\n",
    "    # If yes, return 'end_interview'\n",
    "    \n",
    "    # TODO: Otherwise return 'continue_questions'\n",
    "    pass\n",
    "\n",
    "def save_interview(state: InterviewState):\n",
    "    \"\"\" Convert interview to string format \"\"\"\n",
    "    \n",
    "    # TODO: Get messages from state\n",
    "    \n",
    "    # TODO: Use get_buffer_string() to convert to text\n",
    "    \n",
    "    # TODO: Return as interview field\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build Interview Graph\n",
    "\n",
    "Assemble your interview system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create StateGraph with InterviewState\n",
    "# Add nodes: generate_question, search_web, search_wikipedia, generate_answer, save_interview\n",
    "\n",
    "# TODO: Add edges:\n",
    "# START -> generate_question\n",
    "# generate_question -> search_web (parallel)\n",
    "# generate_question -> search_wikipedia (parallel)\n",
    "# Both searches -> generate_answer\n",
    "# generate_answer -> route_conversation (conditional)\n",
    "# route: continue_questions -> generate_question, end_interview -> save_interview\n",
    "# save_interview -> END\n",
    "\n",
    "# TODO: Compile with MemorySaver\n",
    "\n",
    "# Display graph\n",
    "# display(Image(interview_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Test Interview System\n",
    "\n",
    "Run a sample interview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test analyst\n",
    "test_analyst = Analyst(\n",
    "    name=\"Dr. Sarah Chen\",\n",
    "    affiliation=\"Climate Technology Institute\",\n",
    "    role=\"Sustainability Researcher\",\n",
    "    description=\"Focuses on renewable energy adoption barriers and policy solutions\"\n",
    ")\n",
    "\n",
    "# TODO: Set up initial interview state\n",
    "topic = \"barriers to renewable energy adoption\"\n",
    "initial_message = HumanMessage(content=f\"I understand you're researching {topic}?\")\n",
    "thread = {\"configurable\": {\"thread_id\": \"interview_test\"}}\n",
    "\n",
    "# TODO: Run interview and display results\n",
    "# result = interview_graph.invoke({\n",
    "#     \"analyst\": test_analyst,\n",
    "#     \"messages\": [initial_message],\n",
    "#     \"max_num_turns\": 2\n",
    "# }, thread)\n",
    "\n",
    "# print(\"Interview completed!\")\n",
    "# print(\"\\nInterview transcript:\")\n",
    "# print(result.get('interview', 'No interview saved'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Checkpoint 3**: Verify Your Solution\n",
    "\n",
    "Your interview system should:\n",
    "- âœ… Generate contextual questions based on analyst persona\n",
    "- âœ… Search multiple sources (web + Wikipedia) in parallel\n",
    "- âœ… Provide well-sourced expert answers\n",
    "- âœ… Control conversation flow based on turn limits or completion phrases\n",
    "- âœ… Save complete interview transcripts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Multi-Source Research Integration (Advanced)\n",
    "\n",
    "## Objective\n",
    "Enhance the interview system with section writing capabilities and integrate multiple research sources.\n",
    "\n",
    "## Background\n",
    "Raw interview transcripts need to be transformed into polished research sections. This exercise focuses on processing interview results and generating structured reports with proper citations.\n",
    "\n",
    "## Your Task\n",
    "\n",
    "1. **Extend Interview State**: Add section writing capability\n",
    "2. **Create Section Writer**: Transform interviews into report sections\n",
    "3. **Add Custom Data Sources**: Integrate additional research sources\n",
    "4. **Test Enhanced Pipeline**: Run complete interview-to-section workflow\n",
    "\n",
    "### Step 1: Enhanced Interview State\n",
    "\n",
    "Extend the interview state to support section generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedInterviewState(MessagesState):\n",
    "    max_num_turns: int\n",
    "    context: Annotated[list, operator.add]\n",
    "    analyst: Analyst\n",
    "    interview: str\n",
    "    # TODO: Add sections field as list for report sections\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Section Writer\n",
    "\n",
    "Create a function to transform interviews into structured sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_writer_instructions = \"\"\"You are an expert technical writer. \n",
    "            \n",
    "Your task is to create a short, digestible section of a report based on source documents.\n",
    "\n",
    "1. Analyze the content of the source documents:\n",
    "- Document names are at the start with <Document> tags\n",
    "        \n",
    "2. Create a report structure using markdown:\n",
    "- Use ## for section title\n",
    "- Use ### for sub-section headers\n",
    "        \n",
    "3. Write the report with this structure:\n",
    "a. Title (## header)\n",
    "b. Summary (### header)  \n",
    "c. Sources (### header)\n",
    "\n",
    "4. Make your title engaging based on the analyst focus: {focus}\n",
    "\n",
    "5. For the summary section:\n",
    "- Provide background context related to the analyst's focus area\n",
    "- Emphasize novel, interesting, or surprising insights\n",
    "- Use numbered citations [1], [2], etc.\n",
    "- Target approximately 400 words maximum\n",
    "- Do not mention interviewer or expert names\n",
    "        \n",
    "6. In the Sources section:\n",
    "- List all sources used with full links/paths\n",
    "- Use newlines between sources\n",
    "- Combine duplicate sources\n",
    "\n",
    "### Sources\n",
    "[1] Source name or link\n",
    "[2] Source name or link\n",
    "\"\"\"\n",
    "\n",
    "def write_section(state: EnhancedInterviewState):\n",
    "    \"\"\" Transform interview and context into structured section \"\"\"\n",
    "    \n",
    "    # TODO: Extract interview, context, and analyst from state\n",
    "    \n",
    "    # TODO: Format system message with analyst description as focus\n",
    "    \n",
    "    # TODO: Create human message with context as source material\n",
    "    \n",
    "    # TODO: Invoke LLM to generate section\n",
    "    \n",
    "    # TODO: Return section content in sections list\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add Custom Data Sources\n",
    "\n",
    "Create additional search capabilities for more diverse sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_academic_papers(state: EnhancedInterviewState):\n",
    "    \"\"\" Simulate academic paper search (placeholder implementation) \"\"\"\n",
    "    \n",
    "    # TODO: For this exercise, create a mock academic source\n",
    "    # In a real implementation, you might use arXiv API, Semantic Scholar, etc.\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
    "    \n",
    "    # Mock academic content based on search query\n",
    "    mock_academic_content = f\"\"\"<Document source=\"academic_db\" paper=\"{search_query.search_query.replace(' ', '_')}_2024.pdf\"/>\n",
    "Academic research findings related to {search_query.search_query}. This paper presents evidence-based insights \n",
    "and methodological approaches relevant to the research question. Key findings include statistical analysis, \n",
    "experimental results, and peer-reviewed conclusions that support the theoretical framework.\n",
    "</Document>\"\"\"\n",
    "    \n",
    "    return {\"context\": [mock_academic_content]}\n",
    "\n",
    "def search_industry_reports(state: EnhancedInterviewState):\n",
    "    \"\"\" Simulate industry report search \"\"\"\n",
    "    \n",
    "    # TODO: Create mock industry report content\n",
    "    # Similar structure to academic search but with industry focus\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Enhanced Interview Graph\n",
    "\n",
    "Create an interview system with section writing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create StateGraph with EnhancedInterviewState\n",
    "# Add all previous nodes plus:\n",
    "# - search_academic_papers\n",
    "# - search_industry_reports  \n",
    "# - write_section\n",
    "\n",
    "# TODO: Update edges to include new search sources in parallel\n",
    "# Add: save_interview -> write_section -> END\n",
    "\n",
    "# TODO: Compile and display\n",
    "# enhanced_interview_graph = ...\n",
    "# display(Image(enhanced_interview_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test Enhanced System\n",
    "\n",
    "Run a complete interview with section generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test analyst focused on a specific domain\n",
    "tech_analyst = Analyst(\n",
    "    name=\"Alex Rodriguez\",\n",
    "    affiliation=\"Future Tech Ventures\",\n",
    "    role=\"Technology Investment Analyst\",\n",
    "    description=\"Evaluates emerging technologies for investment potential, focusing on market viability, technical feasibility, and competitive advantages\"\n",
    ")\n",
    "\n",
    "# TODO: Run enhanced interview system\n",
    "topic = \"quantum computing commercialization prospects\"\n",
    "# result = enhanced_interview_graph.invoke({\n",
    "#     \"analyst\": tech_analyst,\n",
    "#     \"messages\": [HumanMessage(content=f\"I'd like to discuss {topic}\")],\n",
    "#     \"max_num_turns\": 2\n",
    "# })\n",
    "\n",
    "# TODO: Display the generated section\n",
    "# if 'sections' in result and result['sections']:\n",
    "#     display(Markdown(result['sections'][0]))\n",
    "# else:\n",
    "#     print(\"No section generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Checkpoint 4**: Verify Your Solution\n",
    "\n",
    "Your enhanced interview system should:\n",
    "- âœ… Generate structured report sections with proper markdown formatting\n",
    "- âœ… Include citations and source references\n",
    "- âœ… Integrate multiple data sources (web, Wikipedia, academic, industry)\n",
    "- âœ… Transform conversational interviews into professional report content\n",
    "- âœ… Handle diverse analyst perspectives and focus areas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Complete Research Assistant Pipeline (Advanced)\n",
    "\n",
    "## Objective\n",
    "Build the full research assistant system that generates analysts, conducts parallel interviews, and produces comprehensive research reports.\n",
    "\n",
    "## Background\n",
    "This is the capstone exercise where you'll combine all previous components into a sophisticated research assistant using LangGraph's `Send()` API for parallel processing and map-reduce patterns.\n",
    "\n",
    "## Your Task\n",
    "\n",
    "1. **Design Complete State Schema**: Create comprehensive state for the full pipeline\n",
    "2. **Implement Map-Reduce Pattern**: Use Send() API for parallel interviews\n",
    "3. **Create Report Generation**: Build introduction, content, and conclusion writers\n",
    "4. **Assemble Final Pipeline**: Connect all components with proper flow control\n",
    "5. **Test Complete System**: Run end-to-end research assistant workflow\n",
    "\n",
    "### Step 1: Complete State Schema\n",
    "\n",
    "Design the master state for the research assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "class ResearchAssistantState(TypedDict):\n",
    "    # TODO: Add fields for complete research pipeline:\n",
    "    # - topic: str (research topic)\n",
    "    # - max_analysts: int (number of analysts)\n",
    "    # - human_analyst_feedback: str (human feedback)\n",
    "    # - analysts: List[Analyst] (generated analysts)\n",
    "    # - sections: Annotated[list, operator.add] (report sections from interviews)\n",
    "    # - introduction: str (report introduction)\n",
    "    # - content: str (main report content)\n",
    "    # - conclusion: str (report conclusion)\n",
    "    # - final_report: str (complete assembled report)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Interview Orchestration\n",
    "\n",
    "Create the map function that launches parallel interviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_all_interviews(state: ResearchAssistantState):\n",
    "    \"\"\" Launch parallel interviews using Send() API \"\"\"\n",
    "    \n",
    "    # TODO: Check if human feedback exists\n",
    "    # If yes, return \"create_analysts\" to regenerate\n",
    "    \n",
    "    # TODO: Otherwise, create Send() messages for each analyst\n",
    "    # Each Send should target \"conduct_interview\" with:\n",
    "    # - analyst: the specific analyst\n",
    "    # - messages: initial HumanMessage about the topic\n",
    "    \n",
    "    # Example structure:\n",
    "    # return [Send(\"conduct_interview\", {\n",
    "    #     \"analyst\": analyst,\n",
    "    #     \"messages\": [HumanMessage(content=f\"I'd like to discuss {topic}\")],\n",
    "    #     \"max_num_turns\": 2\n",
    "    # }) for analyst in state[\"analysts\"]]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Report Writers\n",
    "\n",
    "Implement functions to generate different parts of the final report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_writer_instructions = \"\"\"You are a technical writer creating a report on: {topic}\n",
    "    \n",
    "You have a team of analysts who each:\n",
    "1. Conducted expert interviews on specific sub-topics\n",
    "2. Wrote findings into memos\n",
    "\n",
    "Your task:\n",
    "1. Analyze the collection of memos from your analysts\n",
    "2. Consolidate insights into a cohesive narrative\n",
    "3. Tie together central ideas from all memos\n",
    "\n",
    "Format requirements:\n",
    "1. Use markdown formatting\n",
    "2. No preamble\n",
    "3. No sub-headings\n",
    "4. Start with: ## Insights\n",
    "5. Preserve citations [1], [2], etc.\n",
    "6. Create consolidated Sources section: ## Sources\n",
    "7. Don't mention analyst names\n",
    "\n",
    "Here are the analyst memos: {context}\"\"\"\n",
    "\n",
    "def write_report(state: ResearchAssistantState):\n",
    "    \"\"\" Consolidate all sections into main report content \"\"\"\n",
    "    \n",
    "    # TODO: Extract sections and topic from state\n",
    "    \n",
    "    # TODO: Join all sections with newlines\n",
    "    \n",
    "    # TODO: Format system message with topic and combined sections\n",
    "    \n",
    "    # TODO: Generate consolidated report content\n",
    "    \n",
    "    # TODO: Return in content field\n",
    "    pass\n",
    "\n",
    "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
    "\n",
    "You will be given all sections of the report.\n",
    "\n",
    "Write a crisp and compelling {section_type} section.\n",
    "\n",
    "Guidelines:\n",
    "- No preamble\n",
    "- Target ~100 words\n",
    "- Use markdown formatting\n",
    "- For introduction: compelling title with # header, then ## Introduction\n",
    "- For conclusion: ## Conclusion header\n",
    "- Preview (intro) or recap (conclusion) all report sections\n",
    "\n",
    "Report sections: {formatted_str_sections}\"\"\"\n",
    "\n",
    "def write_introduction(state: ResearchAssistantState):\n",
    "    \"\"\" Generate report introduction \"\"\"\n",
    "    \n",
    "    # TODO: Extract sections and topic\n",
    "    # TODO: Join sections and format instructions\n",
    "    # TODO: Generate introduction\n",
    "    # TODO: Return in introduction field\n",
    "    pass\n",
    "\n",
    "def write_conclusion(state: ResearchAssistantState):\n",
    "    \"\"\" Generate report conclusion \"\"\"\n",
    "    \n",
    "    # TODO: Similar to write_introduction but for conclusion\n",
    "    pass\n",
    "\n",
    "def finalize_report(state: ResearchAssistantState):\n",
    "    \"\"\" Assemble complete final report \"\"\"\n",
    "    \n",
    "    # TODO: Extract introduction, content, and conclusion\n",
    "    \n",
    "    # TODO: Clean up content format (remove \"## Insights\" prefix if present)\n",
    "    \n",
    "    # TODO: Handle sources section separation if needed\n",
    "    \n",
    "    # TODO: Assemble: introduction + \"\\n\\n---\\n\\n\" + content + \"\\n\\n---\\n\\n\" + conclusion\n",
    "    \n",
    "    # TODO: Add sources section if extracted\n",
    "    \n",
    "    # TODO: Return in final_report field\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Assemble Master Graph\n",
    "\n",
    "Connect all components into the complete research assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create StateGraph with ResearchAssistantState\n",
    "# Add nodes:\n",
    "# - create_analysts_with_feedback (from Exercise 2)\n",
    "# - human_feedback\n",
    "# - conduct_interview (use enhanced_interview_graph from Exercise 4)\n",
    "# - write_report\n",
    "# - write_introduction  \n",
    "# - write_conclusion\n",
    "# - finalize_report\n",
    "\n",
    "# TODO: Add edges:\n",
    "# START -> create_analysts_with_feedback\n",
    "# create_analysts_with_feedback -> human_feedback\n",
    "# human_feedback -> initiate_all_interviews (conditional)\n",
    "# conduct_interview -> write_report (parallel)\n",
    "# conduct_interview -> write_introduction (parallel) \n",
    "# conduct_interview -> write_conclusion (parallel)\n",
    "# [write_report, write_introduction, write_conclusion] -> finalize_report\n",
    "# finalize_report -> END\n",
    "\n",
    "# TODO: Compile with interrupt_before=['human_feedback']\n",
    "\n",
    "# research_assistant = builder.compile(interrupt_before=['human_feedback'], checkpointer=MemorySaver())\n",
    "# display(Image(research_assistant.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test Complete Research Assistant\n",
    "\n",
    "Run the full end-to-end workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up research parameters\n",
    "research_topic = \"The impact of edge computing on IoT device performance and security\"\n",
    "max_analysts = 3\n",
    "thread = {\"configurable\": {\"thread_id\": \"final_research\"}}\n",
    "\n",
    "print(f\"Starting research on: {research_topic}\")\n",
    "print(f\"Generating {max_analysts} analysts...\")\n",
    "\n",
    "# TODO: Run until first interruption (human feedback)\n",
    "# for event in research_assistant.stream({\"topic\": research_topic, \"max_analysts\": max_analysts}, thread):\n",
    "#     analysts = event.get('analysts', '')\n",
    "#     if analysts:\n",
    "#         print(f\"\\nGenerated {len(analysts)} analysts:\")\n",
    "#         for analyst in analysts:\n",
    "#             print(f\"- {analyst.name} ({analyst.role})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Provide feedback or continue without feedback\n",
    "# Option 1: Provide feedback\n",
    "# feedback = \"Add a cybersecurity specialist focused on IoT vulnerabilities\"\n",
    "# research_assistant.update_state(thread, {\"human_analyst_feedback\": feedback}, as_node=\"human_feedback\")\n",
    "\n",
    "# Option 2: Continue without feedback\n",
    "research_assistant.update_state(thread, {\"human_analyst_feedback\": None}, as_node=\"human_feedback\")\n",
    "\n",
    "print(\"Proceeding with research...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Continue execution and monitor progress\n",
    "# for event in research_assistant.stream(None, thread, stream_mode=\"updates\"):\n",
    "#     node_name = next(iter(event.keys()))\n",
    "#     print(f\"Executing: {node_name}\")\n",
    "    \n",
    "#     if node_name == \"conduct_interview\":\n",
    "#         print(\"  -> Conducting interviews in parallel...\")\n",
    "#     elif node_name in [\"write_report\", \"write_introduction\", \"write_conclusion\"]:\n",
    "#         print(f\"  -> Generating {node_name.replace('write_', '')}...\")\n",
    "#     elif node_name == \"finalize_report\":\n",
    "#         print(\"  -> Assembling final report...\")\n",
    "\n",
    "print(\"Research completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display final research report\n",
    "# final_state = research_assistant.get_state(thread)\n",
    "# final_report = final_state.values.get('final_report')\n",
    "\n",
    "# if final_report:\n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "#     print(\"FINAL RESEARCH REPORT\")\n",
    "#     print(\"=\"*80)\n",
    "#     display(Markdown(final_report))\n",
    "# else:\n",
    "#     print(\"No final report generated\")\n",
    "\n",
    "# TODO: Display summary statistics\n",
    "# sections = final_state.values.get('sections', [])\n",
    "# print(f\"\\nReport generated from {len(sections)} analyst interviews\")\n",
    "# print(f\"Total report length: ~{len(final_report.split()) if final_report else 0} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ **Final Checkpoint**: Verify Complete System\n",
    "\n",
    "Your complete research assistant should:\n",
    "- âœ… Generate diverse analysts with human feedback capability\n",
    "- âœ… Conduct multiple interviews in parallel using Send() API\n",
    "- âœ… Integrate multiple data sources for comprehensive research\n",
    "- âœ… Transform interviews into structured report sections\n",
    "- âœ… Generate cohesive introduction, main content, and conclusion\n",
    "- âœ… Assemble professional final report with proper citations\n",
    "- âœ… Handle error cases and provide meaningful feedback\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've successfully built a sophisticated multi-agent research assistant using LangGraph! \n",
    "\n",
    "## What You've Accomplished\n",
    "\n",
    "Through these exercises, you've mastered:\n",
    "\n",
    "1. **Multi-Agent System Design**: Created specialized analyst personas with distinct expertise\n",
    "2. **Human-in-the-Loop Workflows**: Built interactive systems that incorporate human feedback\n",
    "3. **Conversational AI Systems**: Implemented multi-turn interview workflows with AI experts\n",
    "4. **Parallel Processing**: Used LangGraph's Send() API for concurrent operations\n",
    "5. **Data Integration**: Combined multiple information sources into cohesive research\n",
    "6. **Report Generation**: Transformed raw conversations into professional research reports\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Consider extending your research assistant with:\n",
    "\n",
    "- **Custom Data Sources**: Integrate domain-specific APIs or databases\n",
    "- **Advanced Citations**: Add more sophisticated reference management\n",
    "- **Quality Control**: Implement fact-checking and source verification\n",
    "- **User Interface**: Create a web interface for easier interaction\n",
    "- **Report Templates**: Support different output formats (executive summary, technical report, etc.)\n",
    "- **Collaborative Features**: Allow multiple users to provide feedback and guidance\n",
    "\n",
    "## Key Patterns You've Learned\n",
    "\n",
    "- **Map-Reduce with LangGraph**: Using Send() API for parallel processing\n",
    "- **State Management**: Designing complex state schemas for multi-step workflows\n",
    "- **Conditional Logic**: Routing based on state conditions and user input\n",
    "- **Human-AI Collaboration**: Building systems that enhance human decision-making\n",
    "- **Structured Output**: Using Pydantic models for reliable AI responses\n",
    "\n",
    "These patterns are fundamental to building production-grade AI applications!\n",
    "\n",
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "1. How might you adapt this research assistant for your specific domain or use case?\n",
    "2. What additional quality controls would be important for production deployment?\n",
    "3. How could you measure and improve the quality of generated reports?\n",
    "4. What ethical considerations should guide the development of AI research assistants?\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [STORM Paper](https://arxiv.org/abs/2402.14207) - Academic foundation for this approach\n",
    "- [LangSmith Tracing](https://docs.smith.langchain.com/) - Monitor and debug your graphs\n",
    "- [Research Assistant Examples](https://github.com/langchain-ai/langchain-academy) - More advanced implementations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}